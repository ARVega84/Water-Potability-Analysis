{"cells":[{"cell_type":"markdown","metadata":{"id":"q75AMytqrau-"},"source":["Alejandro Rafael Vega Saavedra"]},{"cell_type":"markdown","metadata":{"id":"u9SnulS1rau_"},"source":["# Proyecto Final Aprendizaje de Máquina"]},{"cell_type":"markdown","metadata":{},"source":["Primero se debe instalar la siguiente librería para importar la base de datos:"]},{"cell_type":"code","execution_count":115,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11576,"status":"ok","timestamp":1700755799157,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"InQefdw4rau_","outputId":"e1232eca-6ceb-4c65-8248-eac052495d59"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ucimlrepo in c:\\users\\alejo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.3)\n"]}],"source":["!pip install ucimlrepo"]},{"cell_type":"code","execution_count":116,"metadata":{"executionInfo":{"elapsed":11330,"status":"ok","timestamp":1700755810471,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"43DwvmXGravA"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n","import xgboost as xgb\n","from sklearn.metrics import accuracy_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data import TensorDataset"]},{"cell_type":"markdown","metadata":{"id":"tewAQ0dYravA"},"source":["## Importacion del dataset y preprocesamiento de datos"]},{"cell_type":"markdown","metadata":{},"source":["Se utiliza la librería instalada anteriormente para importar la base de datos y se le hace get_dummies a las variables binarias."]},{"cell_type":"code","execution_count":117,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2246,"status":"ok","timestamp":1700755898029,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"ArmYZuQJravB","outputId":"676aa238-1dac-47cf-9c34-07fb984b005c"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'uci_id': 891, 'name': 'CDC Diabetes Health Indicators', 'repository_url': 'https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators', 'data_url': 'https://archive.ics.uci.edu/static/public/891/data.csv', 'abstract': 'The Diabetes Health Indicators Dataset contains healthcare statistics and lifestyle survey information about people in general along with their diagnosis of diabetes. The 35 features consist of some demographics, lab test results, and answers to survey questions for each patient. The target variable for classification is whether a patient has diabetes, is pre-diabetic, or healthy. ', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Tabular', 'Multivariate'], 'num_instances': 253680, 'num_features': 21, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Sex', 'Age', 'Education Level', 'Income'], 'target_col': ['Diabetes_binary'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2017, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C53919', 'creators': [], 'intro_paper': {'title': 'Incidence of End-Stage Renal Disease Attributed to Diabetes Among Persons with Diagnosed Diabetes — United States and Puerto Rico, 2000–2014', 'authors': 'Nilka Rios Burrows, MPH; Israel Hora, PhD; Linda S. Geiss, MA; Edward W. Gregg, PhD; Ann Albright, PhD', 'published_in': 'Morbidity and Mortality Weekly Report', 'year': 2017, 'url': 'https://www.cdc.gov/mmwr/volumes/66/wr/mm6643a2.htm', 'doi': None}, 'additional_info': {'summary': 'Dataset link: https://www.cdc.gov/brfss/annual_data/annual_2014.html', 'purpose': 'To better understand the relationship between  lifestyle and diabetes in the US', 'funded_by': 'The CDC', 'instances_represent': 'Each row represents a person participating in this study.', 'recommended_data_splits': 'Cross validation or a fixed train-test split could be used.', 'sensitive_data': '- Gender\\n- Income\\n- Education level', 'preprocessing_description': 'Bucketing of age', 'variable_info': '- Diabetes diagnosis\\n- Demographics (race, sex)\\n- Personal information (income, educations)\\n- Health history (drinking, smoking, mental health, physical health)', 'citation': None}, 'external_url': 'https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset'}\n","                    name     role     type      demographic  \\\n","0                     ID       ID  Integer             None   \n","1        Diabetes_binary   Target   Binary             None   \n","2                 HighBP  Feature   Binary             None   \n","3               HighChol  Feature   Binary             None   \n","4              CholCheck  Feature   Binary             None   \n","5                    BMI  Feature  Integer             None   \n","6                 Smoker  Feature   Binary             None   \n","7                 Stroke  Feature   Binary             None   \n","8   HeartDiseaseorAttack  Feature   Binary             None   \n","9           PhysActivity  Feature   Binary             None   \n","10                Fruits  Feature   Binary             None   \n","11               Veggies  Feature   Binary             None   \n","12     HvyAlcoholConsump  Feature   Binary             None   \n","13         AnyHealthcare  Feature   Binary             None   \n","14           NoDocbcCost  Feature   Binary             None   \n","15               GenHlth  Feature  Integer             None   \n","16              MentHlth  Feature  Integer             None   \n","17              PhysHlth  Feature  Integer             None   \n","18              DiffWalk  Feature   Binary             None   \n","19                   Sex  Feature   Binary              Sex   \n","20                   Age  Feature  Integer              Age   \n","21             Education  Feature  Integer  Education Level   \n","22                Income  Feature  Integer           Income   \n","\n","                                          description units missing_values  \n","0                                          Patient ID  None             no  \n","1         0 = no diabetes 1 = prediabetes or diabetes  None             no  \n","2                          0 = no high BP 1 = high BP  None             no  \n","3        0 = no high cholesterol 1 = high cholesterol  None             no  \n","4   0 = no cholesterol check in 5 years 1 = yes ch...  None             no  \n","5                                     Body Mass Index  None             no  \n","6   Have you smoked at least 100 cigarettes in you...  None             no  \n","7        (Ever told) you had a stroke. 0 = no 1 = yes  None             no  \n","8   coronary heart disease (CHD) or myocardial inf...  None             no  \n","9   physical activity in past 30 days - not includ...  None             no  \n","10  Consume Fruit 1 or more times per day 0 = no 1...  None             no  \n","11  Consume Vegetables 1 or more times per day 0 =...  None             no  \n","12  Heavy drinkers (adult men having more than 14 ...  None             no  \n","13  Have any kind of health care coverage, includi...  None             no  \n","14  Was there a time in the past 12 months when yo...  None             no  \n","15  Would you say that in general your health is: ...  None             no  \n","16  Now thinking about your mental health, which i...  None             no  \n","17  Now thinking about your physical health, which...  None             no  \n","18  Do you have serious difficulty walking or clim...  None             no  \n","19                                0 = female 1 = male  None             no  \n","20  13-level age category (_AGEG5YR see codebook) ...  None             no  \n","21  Education level (EDUCA see codebook) scale 1-6...  None             no  \n","22  Income scale (INCOME2 see codebook) scale 1-8 ...  None             no  \n"]}],"source":["from ucimlrepo import fetch_ucirepo\n","\n","# fetch dataset\n","cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n","\n","# data\n","x = cdc_diabetes_health_indicators.data.features\n","y = cdc_diabetes_health_indicators.data.targets\n","\n","# metadata\n","print(cdc_diabetes_health_indicators.metadata)\n","\n","# variable information\n","print(cdc_diabetes_health_indicators.variables)\n","\n","x = pd.get_dummies(x, columns = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity',\n","                                 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex'], drop_first = True)"]},{"cell_type":"code","execution_count":118,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"elapsed":193,"status":"ok","timestamp":1700755899972,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"qKnoqhNDravB","outputId":"2678a236-50cf-4398-89b9-fbc0250271ae"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BMI</th>\n","      <th>GenHlth</th>\n","      <th>MentHlth</th>\n","      <th>PhysHlth</th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Income</th>\n","      <th>HighBP_1</th>\n","      <th>HighChol_1</th>\n","      <th>CholCheck_1</th>\n","      <th>...</th>\n","      <th>Stroke_1</th>\n","      <th>HeartDiseaseorAttack_1</th>\n","      <th>PhysActivity_1</th>\n","      <th>Fruits_1</th>\n","      <th>Veggies_1</th>\n","      <th>HvyAlcoholConsump_1</th>\n","      <th>AnyHealthcare_1</th>\n","      <th>NoDocbcCost_1</th>\n","      <th>DiffWalk_1</th>\n","      <th>Sex_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40</td>\n","      <td>5</td>\n","      <td>18</td>\n","      <td>15</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>25</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28</td>\n","      <td>5</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["   BMI  GenHlth  MentHlth  PhysHlth  Age  Education  Income  HighBP_1  \\\n","0   40        5        18        15    9          4       3         1   \n","1   25        3         0         0    7          6       1         0   \n","2   28        5        30        30    9          4       8         1   \n","3   27        2         0         0   11          3       6         1   \n","4   24        2         3         0   11          5       4         1   \n","\n","   HighChol_1  CholCheck_1  ...  Stroke_1  HeartDiseaseorAttack_1  \\\n","0           1            1  ...         0                       0   \n","1           0            0  ...         0                       0   \n","2           1            1  ...         0                       0   \n","3           0            1  ...         0                       0   \n","4           1            1  ...         0                       0   \n","\n","   PhysActivity_1  Fruits_1  Veggies_1  HvyAlcoholConsump_1  AnyHealthcare_1  \\\n","0               0         0          1                    0                1   \n","1               1         0          0                    0                0   \n","2               0         1          0                    0                1   \n","3               1         1          1                    0                1   \n","4               1         1          1                    0                1   \n","\n","   NoDocbcCost_1  DiffWalk_1  Sex_1  \n","0              0           1      0  \n","1              1           0      0  \n","2              1           1      0  \n","3              0           0      0  \n","4              0           0      0  \n","\n","[5 rows x 21 columns]"]},"execution_count":118,"metadata":{},"output_type":"execute_result"}],"source":["x.head()"]},{"cell_type":"code","execution_count":119,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":208,"status":"ok","timestamp":1700755901091,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"CuvQHcI2ravB","outputId":"7269da37-1f4a-4d03-ed28-20611dcb9a72"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Diabetes_binary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Diabetes_binary\n","0                0\n","1                0\n","2                0\n","3                0\n","4                0"]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"source":["y.head()"]},{"cell_type":"markdown","metadata":{"id":"85pIbZ9oravB"},"source":["## Análisis inicial de los datos"]},{"cell_type":"markdown","metadata":{"id":"yUo_zPKVHFsH"},"source":["### Algoritmos de ensamble"]},{"cell_type":"code","execution_count":120,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1700755902684,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"WpY52tX4ravB","outputId":"05d848b1-6350-4a4a-b6ad-70fb7b405968"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BMI</th>\n","      <th>GenHlth</th>\n","      <th>MentHlth</th>\n","      <th>PhysHlth</th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Income</th>\n","      <th>HighBP_1</th>\n","      <th>HighChol_1</th>\n","      <th>CholCheck_1</th>\n","      <th>...</th>\n","      <th>Stroke_1</th>\n","      <th>HeartDiseaseorAttack_1</th>\n","      <th>PhysActivity_1</th>\n","      <th>Fruits_1</th>\n","      <th>Veggies_1</th>\n","      <th>HvyAlcoholConsump_1</th>\n","      <th>AnyHealthcare_1</th>\n","      <th>NoDocbcCost_1</th>\n","      <th>DiffWalk_1</th>\n","      <th>Sex_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>31141</th>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>98230</th>\n","      <td>34</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>89662</th>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>12</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>208255</th>\n","      <td>27</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>233415</th>\n","      <td>24</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["        BMI  GenHlth  MentHlth  PhysHlth  Age  Education  Income  HighBP_1  \\\n","31141    20        2         0         0   12          6       8         0   \n","98230    34        3         0         0    8          5       8         0   \n","89662    24        2         0         5   12          5       6         1   \n","208255   27        1         0         0    5          6       7         0   \n","233415   24        3         0         0   12          4       6         0   \n","\n","        HighChol_1  CholCheck_1  ...  Stroke_1  HeartDiseaseorAttack_1  \\\n","31141            1            1  ...         0                       0   \n","98230            0            1  ...         0                       0   \n","89662            1            1  ...         0                       0   \n","208255           1            1  ...         0                       0   \n","233415           1            1  ...         0                       0   \n","\n","        PhysActivity_1  Fruits_1  Veggies_1  HvyAlcoholConsump_1  \\\n","31141                1         1          1                    0   \n","98230                1         0          1                    0   \n","89662                1         1          1                    0   \n","208255               1         1          1                    0   \n","233415               1         1          1                    0   \n","\n","        AnyHealthcare_1  NoDocbcCost_1  DiffWalk_1  Sex_1  \n","31141                 1              0           0      1  \n","98230                 1              0           0      1  \n","89662                 1              0           0      1  \n","208255                1              0           0      1  \n","233415                1              0           1      0  \n","\n","[5 rows x 21 columns]"]},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["col = x.columns\n","y = np.ravel(y)\n","\n","xtr, xte, ytr, yte = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","\n","pd.DataFrame(xtr, columns = col).head()"]},{"cell_type":"code","execution_count":121,"metadata":{"executionInfo":{"elapsed":71278,"status":"ok","timestamp":1700755974663,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"lfS-XCX9ravC"},"outputs":[],"source":["# Entrenar un modelo de Random Forest\n","rf_classifier = RandomForestClassifier(random_state=42)\n","rf_classifier.fit(xtr, ytr)\n","rf_predictions = rf_classifier.predict(xte)\n","\n","# Entrenar un modelo de AdaBoost\n","ada_classifier = AdaBoostClassifier(random_state=42)\n","ada_classifier.fit(xtr, ytr)\n","ada_predictions = ada_classifier.predict(xte)\n","\n","# Entrenar un modelo de Gradient Boosting\n","gb_classifier = GradientBoostingClassifier(random_state=42)\n","gb_classifier.fit(xtr, ytr)\n","gb_predictions = gb_classifier.predict(xte)\n","\n","# Entrenar un modelo de XGBoost\n","xgb_classifier = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n","xgb_classifier.fit(xtr, ytr)\n","xgb_predictions = xgb_classifier.predict(xte)"]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1700755974665,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"IbkY5zssravC","outputId":"31085209-b952-437b-a1c5-c151c17e6d85"},"outputs":[{"data":{"text/plain":["{'Random Forest Accuracy': 0.8597445600756859,\n"," 'AdaBoost Accuracy': 0.8664262062440871,\n"," 'Gradient Boosting Accuracy': 0.8675102491327656,\n"," 'XGBoost Accuracy': 0.8667612740460423}"]},"execution_count":122,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluar el rendimiento de cada modelo\n","rf_accuracy = accuracy_score(yte, rf_predictions)\n","ada_accuracy = accuracy_score(yte, ada_predictions)\n","gb_accuracy = accuracy_score(yte, gb_predictions)\n","xgb_accuracy = accuracy_score(yte, xgb_predictions)\n","\n","# Mostrar la precisión de cada modelo\n","{'Random Forest Accuracy': rf_accuracy, 'AdaBoost Accuracy': ada_accuracy, 'Gradient Boosting Accuracy': gb_accuracy, 'XGBoost Accuracy': xgb_accuracy}"]},{"cell_type":"markdown","metadata":{"id":"fe_erwaGuAQW"},"source":["### Árbol de clasificación"]},{"cell_type":"code","execution_count":123,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1435,"status":"ok","timestamp":1700755976093,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"JG-KaVFOuHM8","outputId":"613013e8-34cd-4bbb-9de0-a6d82044da74"},"outputs":[{"name":"stdout","output_type":"stream","text":[" DecisionTreeClassifier Accuracy: 0.7967321034374014\n"]}],"source":["xtr, xte, ytr, yte = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","\n","model = DecisionTreeClassifier()\n","model.fit(xtr, ytr)\n","ypr = model.predict(xte)\n","\n","accuracy = accuracy_score(yte, ypr)\n","print(\" DecisionTreeClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"8nzFUZfMvmLi"},"source":["### Clasificación con k-vecinos"]},{"cell_type":"code","execution_count":124,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":161854,"status":"ok","timestamp":1700756137935,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"HqzWYa83v0_p","outputId":"9febdd4a-3227-4fc5-c330-65a1beec69b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["KNeighborsClassifier Accuracy: 0.8052073478397982\n"]}],"source":["xtr, xte, ytr, yte = train_test_split(x, y, test_size = 0.2, random_state = 42)\n","\n","xtr = np.ascontiguousarray(xtr)\n","xte = np.ascontiguousarray(xte)\n","\n","model = KNeighborsClassifier(n_neighbors=1)\n","model.fit(xtr, ytr)\n","ypr = model.predict(xte)\n","\n","accuracy = accuracy_score(yte, ypr)\n","print(\"KNeighborsClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"rEdvmQQbravC"},"source":["### Redes neuronales"]},{"cell_type":"markdown","metadata":{"id":"mw3ZbtidravC"},"source":["#### Conjuntos de entrenamiento, validación y test"]},{"cell_type":"markdown","metadata":{"id":"ZQulxKhJravC"},"source":["A continuación se dividirá la base de datos en los conjuntos de entrenamiento, validación y test para el modelo. Para entrenamiento se dejará el 80% de los datos, y para validación y test 10% para cada uno."]},{"cell_type":"code","execution_count":125,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":245,"status":"ok","timestamp":1700760066799,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"W8UoxaqSravC","outputId":"df267417-47ab-4395-e9d7-ab7fb19b8b2a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BMI</th>\n","      <th>GenHlth</th>\n","      <th>MentHlth</th>\n","      <th>PhysHlth</th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Income</th>\n","      <th>HighBP_1</th>\n","      <th>HighChol_1</th>\n","      <th>CholCheck_1</th>\n","      <th>...</th>\n","      <th>HeartDiseaseorAttack_1</th>\n","      <th>PhysActivity_1</th>\n","      <th>Fruits_1</th>\n","      <th>Veggies_1</th>\n","      <th>HvyAlcoholConsump_1</th>\n","      <th>AnyHealthcare_1</th>\n","      <th>NoDocbcCost_1</th>\n","      <th>DiffWalk_1</th>\n","      <th>Sex_1</th>\n","      <th>Diabetes_binary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40</td>\n","      <td>5</td>\n","      <td>18</td>\n","      <td>15</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>25</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28</td>\n","      <td>5</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>253675</th>\n","      <td>45</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253676</th>\n","      <td>18</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>253677</th>\n","      <td>28</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253678</th>\n","      <td>23</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253679</th>\n","      <td>25</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>253680 rows × 22 columns</p>\n","</div>"],"text/plain":["        BMI  GenHlth  MentHlth  PhysHlth  Age  Education  Income  HighBP_1  \\\n","0        40        5        18        15    9          4       3         1   \n","1        25        3         0         0    7          6       1         0   \n","2        28        5        30        30    9          4       8         1   \n","3        27        2         0         0   11          3       6         1   \n","4        24        2         3         0   11          5       4         1   \n","...     ...      ...       ...       ...  ...        ...     ...       ...   \n","253675   45        3         0         5    5          6       7         1   \n","253676   18        4         0         0   11          2       4         1   \n","253677   28        1         0         0    2          5       2         0   \n","253678   23        3         0         0    7          5       1         1   \n","253679   25        2         0         0    9          6       2         1   \n","\n","        HighChol_1  CholCheck_1  ...  HeartDiseaseorAttack_1  PhysActivity_1  \\\n","0                1            1  ...                       0               0   \n","1                0            0  ...                       0               1   \n","2                1            1  ...                       0               0   \n","3                0            1  ...                       0               1   \n","4                1            1  ...                       0               1   \n","...            ...          ...  ...                     ...             ...   \n","253675           1            1  ...                       0               0   \n","253676           1            1  ...                       0               0   \n","253677           0            1  ...                       0               1   \n","253678           0            1  ...                       0               0   \n","253679           1            1  ...                       1               1   \n","\n","        Fruits_1  Veggies_1  HvyAlcoholConsump_1  AnyHealthcare_1  \\\n","0              0          1                    0                1   \n","1              0          0                    0                0   \n","2              1          0                    0                1   \n","3              1          1                    0                1   \n","4              1          1                    0                1   \n","...          ...        ...                  ...              ...   \n","253675         1          1                    0                1   \n","253676         0          0                    0                1   \n","253677         1          0                    0                1   \n","253678         1          1                    0                1   \n","253679         1          0                    0                1   \n","\n","        NoDocbcCost_1  DiffWalk_1  Sex_1  Diabetes_binary  \n","0                   0           1      0                0  \n","1                   1           0      0                0  \n","2                   1           1      0                0  \n","3                   0           0      0                0  \n","4                   0           0      0                0  \n","...               ...         ...    ...              ...  \n","253675              0           0      1                0  \n","253676              0           1      0                1  \n","253677              0           0      0                0  \n","253678              0           0      1                0  \n","253679              0           0      0                1  \n","\n","[253680 rows x 22 columns]"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["d = x.copy()\n","d['Diabetes_binary'] = y.tolist()\n","d"]},{"cell_type":"code","execution_count":126,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1700760067376,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"RdQ3kwbPravC"},"outputs":[],"source":["d = d.sample(n = 10000, random_state = 42)\n","\n","train = d.iloc[:8000,:]   #Equivale al 80% de los datos.\n","val = d.iloc[8000:9000,:] #Equivale al 10% de los datos.\n","test = d.iloc[9000:,:]    #Equivale al 10% de los datos."]},{"cell_type":"markdown","metadata":{"id":"f-ZWZzxxravD"},"source":["#### Creación de tensores y DataLoaders"]},{"cell_type":"code","execution_count":127,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700760068145,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"I6IniZI3ravD"},"outputs":[],"source":["class MyDataset():\n","\n","  def __init__(self,df,target_column):\n","\n","    y = df[target_column].values\n","    X = df.drop(target_column, axis = 1).values\n","    self.X = torch.tensor(X, dtype = torch.float32)\n","    self.y = torch.tensor(y, dtype = torch.float32)\n","\n","  def __len__(self):\n","    return len(self.y)\n","\n","  def __getitem__(self,idx):\n","    return self.X[idx],self.y[idx]"]},{"cell_type":"markdown","metadata":{"id":"qkeWYIQ1ravD"},"source":["Convertir los conjuntos en tensores."]},{"cell_type":"code","execution_count":128,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700760068447,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"LlQQFWuyravD"},"outputs":[],"source":["traint = MyDataset(train, 'Diabetes_binary')\n","testt = MyDataset(test, 'Diabetes_binary')\n","valt = MyDataset(val, 'Diabetes_binary')"]},{"cell_type":"markdown","metadata":{"id":"kfYj43CuravD"},"source":["Crear los DataLoaders."]},{"cell_type":"code","execution_count":129,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700760068691,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"8Xc1jKSSravD"},"outputs":[],"source":["traind = DataLoader(traint, batch_size = 2,\n","                            shuffle = False,\n","                            num_workers = 0,\n","                            collate_fn = None,\n","                            pin_memory = False,)\n","\n","testd = DataLoader(testt, batch_size = 3,\n","                          shuffle = False,\n","                          num_workers = 0,\n","                          collate_fn = None,\n","                          pin_memory = False,)\n","\n","vald = DataLoader(valt, batch_size = 3,\n","                        shuffle = False,\n","                        num_workers = 0,\n","                        collate_fn = None,\n","                        pin_memory = False,)"]},{"cell_type":"markdown","metadata":{"id":"KxMYy6eUravD"},"source":["#### Definición de la clase Net"]},{"cell_type":"code","execution_count":130,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700760069266,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"kDpjj0LFravD"},"outputs":[],"source":["class Net(nn.Module):\n","\n","    def __init__(self, num_inputs, num_hidden, num_outputs):\n","        super().__init__()\n","\n","        self.fc1 = nn.Linear(num_inputs, num_hidden)\n","        self.act_fn = nn.Sigmoid()\n","        self.fc2 = nn.Linear(num_hidden, num_outputs)\n","\n","    def forward(self, x):\n","\n","        x = self.fc1(x)\n","        x = self.act_fn(x)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"iqRGvclTravD"},"source":["Revisar el dispositivo que se está usando."]},{"cell_type":"code","execution_count":131,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1700760069541,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"hLFwcW3EravD","outputId":"e8561c0f-0d91-49d4-a8a1-c2b93e1c3fe5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Is the GPU available? False\n","Device: cpu\n"]}],"source":["gpu_avail = torch.cuda.is_available()\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","print(f\"Is the GPU available? {gpu_avail}\")\n","print(\"Device:\", device)"]},{"cell_type":"markdown","metadata":{"id":"czW4jFbVravE"},"source":["Creación del modelo, el optimizador y la función de costo."]},{"cell_type":"code","execution_count":132,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1700760069786,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"rpauJ9lyravE"},"outputs":[],"source":["model = Net(num_inputs = 21, num_hidden = 3, num_outputs = 1)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n","criterion = nn.MSELoss()"]},{"cell_type":"markdown","metadata":{"id":"1pFl1cxhravE"},"source":["#### Entrenamiento"]},{"cell_type":"code","execution_count":133,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700760070541,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"Nbqt9khpravE"},"outputs":[],"source":["model.to(device)\n","def train_model(model, optimizer, loss_module, train_loader, valid_loader, num_epochs):\n","\n","  valid_loss_min = np.inf\n","\n","  for i in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","\n","    for data, target in train_loader:\n","        atributes = data.to(device)\n","        labels = target.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        pred = model(atributes)\n","        pred = pred.squeeze(dim = 1)\n","\n","        loss = loss_module(pred, labels.float())\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        train_loss += loss.item() * data.size(0)\n","\n","    train_loss = train_loss/len(train_loader.dataset)\n","\n","    model.eval()\n","\n","    for data,target in valid_loader:\n","      data = data.to(device)\n","      target = target.to(device)\n","      output = model(data)\n","      loss = criterion(output, target)\n","      valid_loss += loss.item()*data.size(0)\n","    valid_loss = valid_loss/len(valid_loader.dataset)\n","\n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","        i, train_loss, valid_loss))\n","\n","    if valid_loss <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        valid_loss))\n","        torch.save(model.state_dict(), 'diabetesmodel.pt')\n","        valid_loss_min = valid_loss"]},{"cell_type":"code","execution_count":134,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40408,"status":"ok","timestamp":1700760110946,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"6M0OCjk4ravE","outputId":"5f563113-7f33-4cd0-939d-ce56c2a80202"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Loss: 0.112558 \tValidation Loss: 0.124215\n","Validation loss decreased (inf --> 0.124215).  Saving model ...\n","Epoch: 1 \tTraining Loss: 0.109761 \tValidation Loss: 0.123138\n","Validation loss decreased (0.124215 --> 0.123138).  Saving model ...\n","Epoch: 2 \tTraining Loss: 0.108777 \tValidation Loss: 0.122769\n","Validation loss decreased (0.123138 --> 0.122769).  Saving model ...\n","Epoch: 3 \tTraining Loss: 0.108016 \tValidation Loss: 0.123044\n","Epoch: 4 \tTraining Loss: 0.107302 \tValidation Loss: 0.123150\n","Epoch: 5 \tTraining Loss: 0.106695 \tValidation Loss: 0.122861\n","Epoch: 6 \tTraining Loss: 0.106180 \tValidation Loss: 0.122609\n","Validation loss decreased (0.122769 --> 0.122609).  Saving model ...\n","Epoch: 7 \tTraining Loss: 0.105731 \tValidation Loss: 0.122510\n","Validation loss decreased (0.122609 --> 0.122510).  Saving model ...\n","Epoch: 8 \tTraining Loss: 0.105337 \tValidation Loss: 0.122489\n","Validation loss decreased (0.122510 --> 0.122489).  Saving model ...\n","Epoch: 9 \tTraining Loss: 0.104993 \tValidation Loss: 0.122469\n","Validation loss decreased (0.122489 --> 0.122469).  Saving model ...\n","Epoch: 10 \tTraining Loss: 0.104691 \tValidation Loss: 0.122421\n","Validation loss decreased (0.122469 --> 0.122421).  Saving model ...\n","Epoch: 11 \tTraining Loss: 0.104422 \tValidation Loss: 0.122379\n","Validation loss decreased (0.122421 --> 0.122379).  Saving model ...\n","Epoch: 12 \tTraining Loss: 0.104184 \tValidation Loss: 0.122407\n","Epoch: 13 \tTraining Loss: 0.103971 \tValidation Loss: 0.122545\n","Epoch: 14 \tTraining Loss: 0.103775 \tValidation Loss: 0.122792\n","Epoch: 15 \tTraining Loss: 0.103592 \tValidation Loss: 0.123111\n","Epoch: 16 \tTraining Loss: 0.103420 \tValidation Loss: 0.123438\n","Epoch: 17 \tTraining Loss: 0.103260 \tValidation Loss: 0.123705\n","Epoch: 18 \tTraining Loss: 0.103112 \tValidation Loss: 0.123880\n","Epoch: 19 \tTraining Loss: 0.102976 \tValidation Loss: 0.123965\n","Epoch: 20 \tTraining Loss: 0.102852 \tValidation Loss: 0.123982\n","Epoch: 21 \tTraining Loss: 0.102738 \tValidation Loss: 0.123946\n","Epoch: 22 \tTraining Loss: 0.102633 \tValidation Loss: 0.123870\n","Epoch: 23 \tTraining Loss: 0.102537 \tValidation Loss: 0.123770\n","Epoch: 24 \tTraining Loss: 0.102447 \tValidation Loss: 0.123664\n","Epoch: 25 \tTraining Loss: 0.102365 \tValidation Loss: 0.123564\n","Epoch: 26 \tTraining Loss: 0.102288 \tValidation Loss: 0.123478\n","Epoch: 27 \tTraining Loss: 0.102217 \tValidation Loss: 0.123406\n","Epoch: 28 \tTraining Loss: 0.102150 \tValidation Loss: 0.123348\n","Epoch: 29 \tTraining Loss: 0.102087 \tValidation Loss: 0.123300\n","Epoch: 30 \tTraining Loss: 0.102027 \tValidation Loss: 0.123259\n","Epoch: 31 \tTraining Loss: 0.101970 \tValidation Loss: 0.123224\n","Epoch: 32 \tTraining Loss: 0.101916 \tValidation Loss: 0.123193\n","Epoch: 33 \tTraining Loss: 0.101864 \tValidation Loss: 0.123164\n","Epoch: 34 \tTraining Loss: 0.101814 \tValidation Loss: 0.123136\n","Epoch: 35 \tTraining Loss: 0.101765 \tValidation Loss: 0.123110\n","Epoch: 36 \tTraining Loss: 0.101719 \tValidation Loss: 0.123086\n","Epoch: 37 \tTraining Loss: 0.101674 \tValidation Loss: 0.123062\n","Epoch: 38 \tTraining Loss: 0.101630 \tValidation Loss: 0.123040\n","Epoch: 39 \tTraining Loss: 0.101588 \tValidation Loss: 0.123020\n","Epoch: 40 \tTraining Loss: 0.101548 \tValidation Loss: 0.123001\n","Epoch: 41 \tTraining Loss: 0.101508 \tValidation Loss: 0.122983\n","Epoch: 42 \tTraining Loss: 0.101471 \tValidation Loss: 0.122967\n","Epoch: 43 \tTraining Loss: 0.101434 \tValidation Loss: 0.122953\n","Epoch: 44 \tTraining Loss: 0.101399 \tValidation Loss: 0.122941\n","Epoch: 45 \tTraining Loss: 0.101365 \tValidation Loss: 0.122930\n","Epoch: 46 \tTraining Loss: 0.101333 \tValidation Loss: 0.122921\n","Epoch: 47 \tTraining Loss: 0.101302 \tValidation Loss: 0.122915\n","Epoch: 48 \tTraining Loss: 0.101272 \tValidation Loss: 0.122912\n","Epoch: 49 \tTraining Loss: 0.101243 \tValidation Loss: 0.122911\n","Epoch: 50 \tTraining Loss: 0.101215 \tValidation Loss: 0.122914\n","Epoch: 51 \tTraining Loss: 0.101188 \tValidation Loss: 0.122921\n","Epoch: 52 \tTraining Loss: 0.101162 \tValidation Loss: 0.122930\n","Epoch: 53 \tTraining Loss: 0.101137 \tValidation Loss: 0.122943\n","Epoch: 54 \tTraining Loss: 0.101112 \tValidation Loss: 0.122959\n","Epoch: 55 \tTraining Loss: 0.101088 \tValidation Loss: 0.122976\n","Epoch: 56 \tTraining Loss: 0.101065 \tValidation Loss: 0.122996\n","Epoch: 57 \tTraining Loss: 0.101042 \tValidation Loss: 0.123018\n","Epoch: 58 \tTraining Loss: 0.101020 \tValidation Loss: 0.123042\n","Epoch: 59 \tTraining Loss: 0.100998 \tValidation Loss: 0.123066\n","Epoch: 60 \tTraining Loss: 0.100977 \tValidation Loss: 0.123093\n","Epoch: 61 \tTraining Loss: 0.100956 \tValidation Loss: 0.123120\n","Epoch: 62 \tTraining Loss: 0.100936 \tValidation Loss: 0.123148\n","Epoch: 63 \tTraining Loss: 0.100916 \tValidation Loss: 0.123177\n","Epoch: 64 \tTraining Loss: 0.100897 \tValidation Loss: 0.123207\n","Epoch: 65 \tTraining Loss: 0.100878 \tValidation Loss: 0.123238\n","Epoch: 66 \tTraining Loss: 0.100859 \tValidation Loss: 0.123269\n","Epoch: 67 \tTraining Loss: 0.100841 \tValidation Loss: 0.123301\n","Epoch: 68 \tTraining Loss: 0.100823 \tValidation Loss: 0.123333\n","Epoch: 69 \tTraining Loss: 0.100806 \tValidation Loss: 0.123365\n","Epoch: 70 \tTraining Loss: 0.100788 \tValidation Loss: 0.123398\n","Epoch: 71 \tTraining Loss: 0.100772 \tValidation Loss: 0.123431\n","Epoch: 72 \tTraining Loss: 0.100755 \tValidation Loss: 0.123464\n","Epoch: 73 \tTraining Loss: 0.100739 \tValidation Loss: 0.123497\n","Epoch: 74 \tTraining Loss: 0.100724 \tValidation Loss: 0.123530\n","Epoch: 75 \tTraining Loss: 0.100708 \tValidation Loss: 0.123563\n","Epoch: 76 \tTraining Loss: 0.100693 \tValidation Loss: 0.123595\n","Epoch: 77 \tTraining Loss: 0.100678 \tValidation Loss: 0.123627\n","Epoch: 78 \tTraining Loss: 0.100664 \tValidation Loss: 0.123659\n","Epoch: 79 \tTraining Loss: 0.100650 \tValidation Loss: 0.123690\n","Epoch: 80 \tTraining Loss: 0.100636 \tValidation Loss: 0.123721\n","Epoch: 81 \tTraining Loss: 0.100622 \tValidation Loss: 0.123751\n","Epoch: 82 \tTraining Loss: 0.100609 \tValidation Loss: 0.123780\n","Epoch: 83 \tTraining Loss: 0.100596 \tValidation Loss: 0.123808\n","Epoch: 84 \tTraining Loss: 0.100583 \tValidation Loss: 0.123836\n","Epoch: 85 \tTraining Loss: 0.100571 \tValidation Loss: 0.123863\n","Epoch: 86 \tTraining Loss: 0.100559 \tValidation Loss: 0.123889\n","Epoch: 87 \tTraining Loss: 0.100547 \tValidation Loss: 0.123914\n","Epoch: 88 \tTraining Loss: 0.100535 \tValidation Loss: 0.123939\n","Epoch: 89 \tTraining Loss: 0.100524 \tValidation Loss: 0.123962\n","Epoch: 90 \tTraining Loss: 0.100513 \tValidation Loss: 0.123984\n","Epoch: 91 \tTraining Loss: 0.100502 \tValidation Loss: 0.124005\n","Epoch: 92 \tTraining Loss: 0.100492 \tValidation Loss: 0.124025\n","Epoch: 93 \tTraining Loss: 0.100482 \tValidation Loss: 0.124044\n","Epoch: 94 \tTraining Loss: 0.100472 \tValidation Loss: 0.124061\n","Epoch: 95 \tTraining Loss: 0.100462 \tValidation Loss: 0.124077\n","Epoch: 96 \tTraining Loss: 0.100453 \tValidation Loss: 0.124091\n","Epoch: 97 \tTraining Loss: 0.100445 \tValidation Loss: 0.124104\n","Epoch: 98 \tTraining Loss: 0.100436 \tValidation Loss: 0.124115\n","Epoch: 99 \tTraining Loss: 0.100429 \tValidation Loss: 0.124123\n"]}],"source":["train_model(model, optimizer, criterion, traind, vald, num_epochs = 100)"]},{"cell_type":"code","execution_count":135,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1700760110947,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"PcGf15UTravE","outputId":"9ad79a09-b1a9-4679-9d75-60a58f46613a"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":135,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load('diabetesmodel.pt'))"]},{"cell_type":"markdown","metadata":{"id":"BoRWjkuCravE"},"source":["#### Evaluar la precisión del modelo"]},{"cell_type":"code","execution_count":136,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1700760110948,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"0fLSH9KNravE"},"outputs":[],"source":["def eval_model(model, data_loader):\n","    model.eval()\n","    true_preds, num_preds = 0., 0.\n","\n","    with torch.no_grad():\n","        for data_inputs, data_labels in data_loader:\n","\n","            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n","            preds = model(data_inputs)\n","            preds = preds.squeeze(dim=1)\n","            preds = torch.sigmoid(preds)\n","            pred_labels = (preds >= 0.5).long()\n","\n","            true_preds += (pred_labels == data_labels).sum()\n","            num_preds += data_labels.shape[0]\n","\n","    acc = true_preds / num_preds\n","    return acc"]},{"cell_type":"code","execution_count":137,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":316,"status":"ok","timestamp":1700760111253,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"HHvVdS1travF","outputId":"d97a6f16-bb13-4bdd-c544-2e327d705db6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model: 13.70%\n"]}],"source":["print(f\"Accuracy of the model: {100.0*eval_model(model, testd):4.2f}%\")"]},{"cell_type":"markdown","metadata":{"id":"6fFa6J9gCzr1"},"source":["## Atributos con mayor ganancia"]},{"cell_type":"markdown","metadata":{},"source":["Ahora se calculan los atributos con mayor ganancia para evaluar los modelos con esos atributos."]},{"cell_type":"code","execution_count":138,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2407,"status":"ok","timestamp":1700757984625,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"UzbryrIwDEOO","outputId":"19cb4faf-af76-4a95-97f0-12d735cd5fd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ganancia para el atributo BMI :  0.13758470960727265\n","Ganancia para el atributo Age :  0.10308230727058107\n","Ganancia para el atributo Income :  0.09952461219887272\n","Ganancia para el atributo HighBP_1 :  0.08920612209111388\n","Ganancia para el atributo PhysHlth :  0.0870992176829414\n","Ganancia para el atributo GenHlth :  0.07442832513723022\n","Ganancia para el atributo Education :  0.07289078570113422\n","Ganancia para el atributo MentHlth :  0.06687087282045902\n","Ganancia para el atributo Smoker_1 :  0.03742594196038871\n","Ganancia para el atributo Fruits_1 :  0.03703998409050273\n","Ganancia para el atributo PhysActivity_1 :  0.03239549832170855\n","Ganancia para el atributo Veggies_1 :  0.028470315593243475\n","Ganancia para el atributo Sex_1 :  0.02619135808351302\n","Ganancia para el atributo DiffWalk_1 :  0.021510643879186806\n","Ganancia para el atributo HeartDiseaseorAttack_1 :  0.018222225544362893\n","Ganancia para el atributo HighChol_1 :  0.01741249747187778\n","Ganancia para el atributo NoDocbcCost_1 :  0.014536518787410352\n","Ganancia para el atributo Stroke_1 :  0.014233442656685085\n","Ganancia para el atributo HvyAlcoholConsump_1 :  0.009009748471622798\n","Ganancia para el atributo AnyHealthcare_1 :  0.008693701856727397\n","Ganancia para el atributo CholCheck_1 :  0.004171170773165231\n"]}],"source":["gm = pd.DataFrame(x, columns = x.columns.values)\n","\n","clf = DecisionTreeClassifier(random_state= 42, criterion = 'entropy')\n","clf.fit(x,y)\n","\n","fi = clf.feature_importances_\n","si = np.argsort(fi)[::-1]\n","\n","for i in si:\n","  fn = gm.columns.values[i]\n","  imp = fi[i]\n","  print(\"Ganancia para el atributo\", fn, \": \", imp)"]},{"cell_type":"markdown","metadata":{"id":"9iQ32FpFF945"},"source":["### Ganancia mayor o igual a 10%"]},{"cell_type":"markdown","metadata":{},"source":["Se seleccionan todos los atributos con ganancia mayor o igual a 0.1 o 10%, los cuales son BMI y Age."]},{"cell_type":"markdown","metadata":{"id":"AKTK9w1MHdGb"},"source":["#### Algoritmos de ensamble"]},{"cell_type":"code","execution_count":139,"metadata":{"executionInfo":{"elapsed":573,"status":"ok","timestamp":1700758460110,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"GpNpos8iGD1c"},"outputs":[],"source":["xg1 = x[['BMI', 'Age']]"]},{"cell_type":"code","execution_count":140,"metadata":{"executionInfo":{"elapsed":25042,"status":"ok","timestamp":1700759052138,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"ORWs7zqtGl1X"},"outputs":[],"source":["xg1tr, xg1te, yg1tr, yg1te = train_test_split(xg1, y, test_size = 0.2, random_state = 42)\n","\n","# Entrenar un modelo de Random Forest\n","rf_classifier = RandomForestClassifier(random_state=42)\n","rf_classifier.fit(xg1tr, yg1tr)\n","rf_predictions = rf_classifier.predict(xg1te)\n","\n","# Entrenar un modelo de AdaBoost\n","ada_classifier = AdaBoostClassifier(random_state=42)\n","ada_classifier.fit(xg1tr, yg1tr)\n","ada_predictions = ada_classifier.predict(xg1te)\n","\n","# Entrenar un modelo de Gradient Boosting\n","gb_classifier = GradientBoostingClassifier(random_state=42)\n","gb_classifier.fit(xg1tr, yg1tr)\n","gb_predictions = gb_classifier.predict(xg1te)\n","\n","# Entrenar un modelo de XGBoost\n","xgb_classifier = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n","xgb_classifier.fit(xg1tr, yg1tr)\n","xgb_predictions = xgb_classifier.predict(xg1te)"]},{"cell_type":"code","execution_count":141,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1700759052140,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"dBQuijoKHV1r","outputId":"71bf39a8-77d4-409c-b79d-f6a75a2af736"},"outputs":[{"data":{"text/plain":["{'Random Forest Accuracy': 0.8613410596026491,\n"," 'AdaBoost Accuracy': 0.8617549668874173,\n"," 'Gradient Boosting Accuracy': 0.8621885840428887,\n"," 'XGBoost Accuracy': 0.8613804793440555}"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluar el rendimiento de cada modelo\n","rf_accuracy = accuracy_score(yg1te, rf_predictions)\n","ada_accuracy = accuracy_score(yg1te, ada_predictions)\n","gb_accuracy = accuracy_score(yg1te, gb_predictions)\n","xgb_accuracy = accuracy_score(yg1te, xgb_predictions)\n","\n","# Mostrar la precisión de cada modelo\n","{'Random Forest Accuracy': rf_accuracy, 'AdaBoost Accuracy': ada_accuracy, 'Gradient Boosting Accuracy': gb_accuracy, 'XGBoost Accuracy': xgb_accuracy}"]},{"cell_type":"markdown","metadata":{},"source":["Aquí se puede ver que, comparado con el modelo inicial, Random Forest aumento su accuracy de 85.9% a 86.1%, mientras que los otros disminuyeron 0.5%."]},{"cell_type":"markdown","metadata":{"id":"5HZPTPptIpDQ"},"source":["#### Árbol de clasificación"]},{"cell_type":"code","execution_count":142,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":571,"status":"ok","timestamp":1700759064001,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"Ehc0mWquHXTE","outputId":"4c51baf9-9314-4b46-88c7-3ad1db049a3e"},"outputs":[{"name":"stdout","output_type":"stream","text":[" DecisionTreeClassifier Accuracy: 0.8614593188268685\n"]}],"source":["xg1tr, xg1te, yg1tr, yg1te = train_test_split(xg1, y, test_size = 0.2, random_state = 42)\n","\n","model = DecisionTreeClassifier()\n","model.fit(xg1tr, yg1tr)\n","yg1pr = model.predict(xg1te)\n","\n","accuracy = accuracy_score(yg1te, yg1pr)\n","print(\" DecisionTreeClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["Comparándolo con el modelo inicial, se puede ver que aumento de 79.% a 86.1%."]},{"cell_type":"markdown","metadata":{"id":"mZ0iXw3dJDBh"},"source":["#### Clasificación con k-vecinos"]},{"cell_type":"code","execution_count":143,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5626,"status":"ok","timestamp":1700759157322,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"EgxgwLW4JGfH","outputId":"58d8e83f-8cb7-49bf-faed-85a45857b514"},"outputs":[{"name":"stdout","output_type":"stream","text":["KNeighborsClassifier Accuracy: 0.8099180069378745\n"]}],"source":["xg1tr, xg1te, yg1tr, yg1te = train_test_split(xg1, y, test_size = 0.2, random_state = 42)\n","\n","xg1tr = np.ascontiguousarray(xg1tr)\n","xg1te = np.ascontiguousarray(xg1te)\n","\n","model = KNeighborsClassifier(n_neighbors=1)\n","model.fit(xg1tr, yg1tr)\n","yg1pr = model.predict(xg1te)\n","\n","accuracy = accuracy_score(yg1te, yg1pr)\n","print(\"KNeighborsClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["Ahora, se puede ver que aumento de 80.5% a 80.9% a comparación con el modelo inicial."]},{"cell_type":"markdown","metadata":{"id":"O9k6AviaJmA2"},"source":["#### Redes neuronales"]},{"cell_type":"code","execution_count":144,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1700760135411,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"U8bHKD6QJoeJ","outputId":"bdb9eb80-12a4-4a8a-98bc-ccaeb1ed8d06"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BMI</th>\n","      <th>Age</th>\n","      <th>Diabetes_binary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40</td>\n","      <td>9</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>25</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28</td>\n","      <td>9</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24</td>\n","      <td>11</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>253675</th>\n","      <td>45</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253676</th>\n","      <td>18</td>\n","      <td>11</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>253677</th>\n","      <td>28</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253678</th>\n","      <td>23</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253679</th>\n","      <td>25</td>\n","      <td>9</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>253680 rows × 3 columns</p>\n","</div>"],"text/plain":["        BMI  Age  Diabetes_binary\n","0        40    9                0\n","1        25    7                0\n","2        28    9                0\n","3        27   11                0\n","4        24   11                0\n","...     ...  ...              ...\n","253675   45    5                0\n","253676   18   11                1\n","253677   28    2                0\n","253678   23    7                0\n","253679   25    9                1\n","\n","[253680 rows x 3 columns]"]},"execution_count":144,"metadata":{},"output_type":"execute_result"}],"source":["dg1 = xg1.copy()\n","dg1['Diabetes_binary'] = y.tolist()\n","dg1"]},{"cell_type":"code","execution_count":145,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1700760135682,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"qUYuIILKJv0C"},"outputs":[],"source":["dg1 = dg1.sample(n = 10000, random_state = 42)\n","\n","traing1 = dg1.iloc[:8000,:]   #Equivale al 80% de los datos.\n","valg1 = dg1.iloc[8000:9000,:] #Equivale al 10% de los datos.\n","testg1 = dg1.iloc[9000:,:]    #Equivale al 10% de los datos."]},{"cell_type":"code","execution_count":146,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700760135682,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"Xbmla3WTKEIT"},"outputs":[],"source":["traintg1 = MyDataset(traing1, 'Diabetes_binary')\n","testtg1 = MyDataset(testg1, 'Diabetes_binary')\n","valtg1 = MyDataset(valg1, 'Diabetes_binary')"]},{"cell_type":"code","execution_count":147,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700760135682,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"Sw7cQfJeKS3E"},"outputs":[],"source":["traindg1 = DataLoader(traintg1, batch_size = 2,\n","                            shuffle = False,\n","                            num_workers = 0,\n","                            collate_fn = None,\n","                            pin_memory = False,)\n","\n","testdg1 = DataLoader(testtg1, batch_size = 3,\n","                          shuffle = False,\n","                          num_workers = 0,\n","                          collate_fn = None,\n","                          pin_memory = False,)\n","\n","valdg1 = DataLoader(valtg1, batch_size = 3,\n","                        shuffle = False,\n","                        num_workers = 0,\n","                        collate_fn = None,\n","                        pin_memory = False,)"]},{"cell_type":"code","execution_count":148,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1700760136142,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"lkfG8iFKKdW0"},"outputs":[],"source":["modelg1 = Net(num_inputs = 2, num_hidden = 3, num_outputs = 1)\n","\n","optimizerg1 = torch.optim.SGD(modelg1.parameters(), lr = 0.01)\n","criteriong1 = nn.MSELoss()"]},{"cell_type":"code","execution_count":149,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700760136508,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"UTJAMLJsKvWd","outputId":"e6021c90-d5ae-4b84-bdf8-f9616f036048"},"outputs":[{"data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=2, out_features=3, bias=True)\n","  (act_fn): Sigmoid()\n","  (fc2): Linear(in_features=3, out_features=1, bias=True)\n",")"]},"execution_count":149,"metadata":{},"output_type":"execute_result"}],"source":["modelg1.to(device)"]},{"cell_type":"code","execution_count":150,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30444,"status":"ok","timestamp":1700760166949,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"xa-Imdz1K9yl","outputId":"b590f95c-a703-44b8-c6ee-cc2d2acfab2c"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Loss: 0.121213 \tValidation Loss: 0.123882\n","Validation loss decreased (inf --> 0.123882).  Saving model ...\n","Epoch: 1 \tTraining Loss: 0.119395 \tValidation Loss: 0.123777\n","Validation loss decreased (0.123882 --> 0.123777).  Saving model ...\n","Epoch: 2 \tTraining Loss: 0.118782 \tValidation Loss: 0.123835\n","Epoch: 3 \tTraining Loss: 0.117961 \tValidation Loss: 0.124578\n","Epoch: 4 \tTraining Loss: 0.117479 \tValidation Loss: 0.124922\n","Epoch: 5 \tTraining Loss: 0.117210 \tValidation Loss: 0.125165\n","Epoch: 6 \tTraining Loss: 0.117015 \tValidation Loss: 0.125404\n","Epoch: 7 \tTraining Loss: 0.116852 \tValidation Loss: 0.125640\n","Epoch: 8 \tTraining Loss: 0.116714 \tValidation Loss: 0.125856\n","Epoch: 9 \tTraining Loss: 0.116596 \tValidation Loss: 0.126039\n","Epoch: 10 \tTraining Loss: 0.116493 \tValidation Loss: 0.126191\n","Epoch: 11 \tTraining Loss: 0.116402 \tValidation Loss: 0.126314\n","Epoch: 12 \tTraining Loss: 0.116319 \tValidation Loss: 0.126415\n","Epoch: 13 \tTraining Loss: 0.116244 \tValidation Loss: 0.126498\n","Epoch: 14 \tTraining Loss: 0.116176 \tValidation Loss: 0.126565\n","Epoch: 15 \tTraining Loss: 0.116113 \tValidation Loss: 0.126619\n","Epoch: 16 \tTraining Loss: 0.116056 \tValidation Loss: 0.126664\n","Epoch: 17 \tTraining Loss: 0.116003 \tValidation Loss: 0.126700\n","Epoch: 18 \tTraining Loss: 0.115954 \tValidation Loss: 0.126729\n","Epoch: 19 \tTraining Loss: 0.115908 \tValidation Loss: 0.126752\n","Epoch: 20 \tTraining Loss: 0.115866 \tValidation Loss: 0.126770\n","Epoch: 21 \tTraining Loss: 0.115828 \tValidation Loss: 0.126785\n","Epoch: 22 \tTraining Loss: 0.115792 \tValidation Loss: 0.126797\n","Epoch: 23 \tTraining Loss: 0.115758 \tValidation Loss: 0.126806\n","Epoch: 24 \tTraining Loss: 0.115728 \tValidation Loss: 0.126814\n","Epoch: 25 \tTraining Loss: 0.115699 \tValidation Loss: 0.126820\n","Epoch: 26 \tTraining Loss: 0.115673 \tValidation Loss: 0.126824\n","Epoch: 27 \tTraining Loss: 0.115648 \tValidation Loss: 0.126828\n","Epoch: 28 \tTraining Loss: 0.115626 \tValidation Loss: 0.126831\n","Epoch: 29 \tTraining Loss: 0.115605 \tValidation Loss: 0.126833\n","Epoch: 30 \tTraining Loss: 0.115585 \tValidation Loss: 0.126835\n","Epoch: 31 \tTraining Loss: 0.115567 \tValidation Loss: 0.126836\n","Epoch: 32 \tTraining Loss: 0.115550 \tValidation Loss: 0.126838\n","Epoch: 33 \tTraining Loss: 0.115534 \tValidation Loss: 0.126839\n","Epoch: 34 \tTraining Loss: 0.115519 \tValidation Loss: 0.126840\n","Epoch: 35 \tTraining Loss: 0.115505 \tValidation Loss: 0.126841\n","Epoch: 36 \tTraining Loss: 0.115492 \tValidation Loss: 0.126842\n","Epoch: 37 \tTraining Loss: 0.115480 \tValidation Loss: 0.126844\n","Epoch: 38 \tTraining Loss: 0.115468 \tValidation Loss: 0.126845\n","Epoch: 39 \tTraining Loss: 0.115457 \tValidation Loss: 0.126846\n","Epoch: 40 \tTraining Loss: 0.115447 \tValidation Loss: 0.126848\n","Epoch: 41 \tTraining Loss: 0.115437 \tValidation Loss: 0.126849\n","Epoch: 42 \tTraining Loss: 0.115427 \tValidation Loss: 0.126851\n","Epoch: 43 \tTraining Loss: 0.115418 \tValidation Loss: 0.126853\n","Epoch: 44 \tTraining Loss: 0.115410 \tValidation Loss: 0.126855\n","Epoch: 45 \tTraining Loss: 0.115401 \tValidation Loss: 0.126857\n","Epoch: 46 \tTraining Loss: 0.115393 \tValidation Loss: 0.126860\n","Epoch: 47 \tTraining Loss: 0.115386 \tValidation Loss: 0.126863\n","Epoch: 48 \tTraining Loss: 0.115378 \tValidation Loss: 0.126866\n","Epoch: 49 \tTraining Loss: 0.115371 \tValidation Loss: 0.126869\n","Epoch: 50 \tTraining Loss: 0.115364 \tValidation Loss: 0.126872\n","Epoch: 51 \tTraining Loss: 0.115357 \tValidation Loss: 0.126876\n","Epoch: 52 \tTraining Loss: 0.115350 \tValidation Loss: 0.126879\n","Epoch: 53 \tTraining Loss: 0.115343 \tValidation Loss: 0.126883\n","Epoch: 54 \tTraining Loss: 0.115336 \tValidation Loss: 0.126888\n","Epoch: 55 \tTraining Loss: 0.115329 \tValidation Loss: 0.126892\n","Epoch: 56 \tTraining Loss: 0.115323 \tValidation Loss: 0.126897\n","Epoch: 57 \tTraining Loss: 0.115316 \tValidation Loss: 0.126902\n","Epoch: 58 \tTraining Loss: 0.115310 \tValidation Loss: 0.126908\n","Epoch: 59 \tTraining Loss: 0.115303 \tValidation Loss: 0.126914\n","Epoch: 60 \tTraining Loss: 0.115297 \tValidation Loss: 0.126920\n","Epoch: 61 \tTraining Loss: 0.115290 \tValidation Loss: 0.126926\n","Epoch: 62 \tTraining Loss: 0.115284 \tValidation Loss: 0.126933\n","Epoch: 63 \tTraining Loss: 0.115277 \tValidation Loss: 0.126940\n","Epoch: 64 \tTraining Loss: 0.115270 \tValidation Loss: 0.126948\n","Epoch: 65 \tTraining Loss: 0.115263 \tValidation Loss: 0.126956\n","Epoch: 66 \tTraining Loss: 0.115256 \tValidation Loss: 0.126964\n","Epoch: 67 \tTraining Loss: 0.115249 \tValidation Loss: 0.126973\n","Epoch: 68 \tTraining Loss: 0.115242 \tValidation Loss: 0.126982\n","Epoch: 69 \tTraining Loss: 0.115235 \tValidation Loss: 0.126992\n","Epoch: 70 \tTraining Loss: 0.115228 \tValidation Loss: 0.127002\n","Epoch: 71 \tTraining Loss: 0.115220 \tValidation Loss: 0.127013\n","Epoch: 72 \tTraining Loss: 0.115212 \tValidation Loss: 0.127025\n","Epoch: 73 \tTraining Loss: 0.115204 \tValidation Loss: 0.127037\n","Epoch: 74 \tTraining Loss: 0.115196 \tValidation Loss: 0.127049\n","Epoch: 75 \tTraining Loss: 0.115188 \tValidation Loss: 0.127063\n","Epoch: 76 \tTraining Loss: 0.115179 \tValidation Loss: 0.127077\n","Epoch: 77 \tTraining Loss: 0.115171 \tValidation Loss: 0.127092\n","Epoch: 78 \tTraining Loss: 0.115162 \tValidation Loss: 0.127108\n","Epoch: 79 \tTraining Loss: 0.115152 \tValidation Loss: 0.127125\n","Epoch: 80 \tTraining Loss: 0.115143 \tValidation Loss: 0.127142\n","Epoch: 81 \tTraining Loss: 0.115133 \tValidation Loss: 0.127161\n","Epoch: 82 \tTraining Loss: 0.115123 \tValidation Loss: 0.127181\n","Epoch: 83 \tTraining Loss: 0.115112 \tValidation Loss: 0.127201\n","Epoch: 84 \tTraining Loss: 0.115102 \tValidation Loss: 0.127223\n","Epoch: 85 \tTraining Loss: 0.115090 \tValidation Loss: 0.127247\n","Epoch: 86 \tTraining Loss: 0.115079 \tValidation Loss: 0.127271\n","Epoch: 87 \tTraining Loss: 0.115067 \tValidation Loss: 0.127297\n","Epoch: 88 \tTraining Loss: 0.115055 \tValidation Loss: 0.127325\n","Epoch: 89 \tTraining Loss: 0.115042 \tValidation Loss: 0.127354\n","Epoch: 90 \tTraining Loss: 0.115029 \tValidation Loss: 0.127385\n","Epoch: 91 \tTraining Loss: 0.115016 \tValidation Loss: 0.127417\n","Epoch: 92 \tTraining Loss: 0.115002 \tValidation Loss: 0.127452\n","Epoch: 93 \tTraining Loss: 0.114987 \tValidation Loss: 0.127488\n","Epoch: 94 \tTraining Loss: 0.114973 \tValidation Loss: 0.127526\n","Epoch: 95 \tTraining Loss: 0.114957 \tValidation Loss: 0.127565\n","Epoch: 96 \tTraining Loss: 0.114942 \tValidation Loss: 0.127607\n","Epoch: 97 \tTraining Loss: 0.114926 \tValidation Loss: 0.127651\n","Epoch: 98 \tTraining Loss: 0.114910 \tValidation Loss: 0.127696\n","Epoch: 99 \tTraining Loss: 0.114893 \tValidation Loss: 0.127744\n"]}],"source":["train_model(modelg1, optimizerg1, criteriong1, traindg1, valdg1, num_epochs = 100)"]},{"cell_type":"code","execution_count":151,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1700760166949,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"52IM-JOOK-8R","outputId":"ea1852f0-88b1-4809-94ef-a217bc15904a"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":151,"metadata":{},"output_type":"execute_result"}],"source":["modelg1.load_state_dict(torch.load('diabetesmodel.pt'))"]},{"cell_type":"code","execution_count":152,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1700760166949,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"tluIcEKVLDH7","outputId":"74fae570-1436-4334-dc95-451137745f9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model: 13.70%\n"]}],"source":["print(f\"Accuracy of the model: {100.0*eval_model(modelg1, testdg1):4.2f}%\")"]},{"cell_type":"markdown","metadata":{},"source":["En este caso se mantuvo igual que el modelo inicial."]},{"cell_type":"markdown","metadata":{"id":"OuL2JzhgOqnR"},"source":["### Ganancia mayor o igual a 5%"]},{"cell_type":"markdown","metadata":{},"source":["Ahora se seleccionan todos los atributos con ganancia mayor o igual a 0.05 o 5%, los cuales son BMI, Age, Income, HighBP_1, PhysHlth, GenHlth, Education, MentHlth."]},{"cell_type":"markdown","metadata":{"id":"4nbxqK0-Oxhc"},"source":["#### Algoritmos de ensamble"]},{"cell_type":"code","execution_count":153,"metadata":{"executionInfo":{"elapsed":198,"status":"ok","timestamp":1700761115769,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"N936CWnuOxhd"},"outputs":[],"source":["xg2 = x[['BMI', 'Age', 'Income', 'HighBP_1', 'PhysHlth', 'GenHlth', 'Education', 'MentHlth']]"]},{"cell_type":"code","execution_count":154,"metadata":{"executionInfo":{"elapsed":47848,"status":"ok","timestamp":1700761164948,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"54Vxx1QbOxhe"},"outputs":[],"source":["xg2tr, xg2te, yg2tr, yg2te = train_test_split(xg2, y, test_size = 0.2, random_state = 42)\n","\n","# Entrenar un modelo de Random Forest\n","rf_classifier = RandomForestClassifier(random_state=42)\n","rf_classifier.fit(xg2tr, yg2tr)\n","rf_predictions = rf_classifier.predict(xg2te)\n","\n","# Entrenar un modelo de AdaBoost\n","ada_classifier = AdaBoostClassifier(random_state=42)\n","ada_classifier.fit(xg2tr, yg2tr)\n","ada_predictions = ada_classifier.predict(xg2te)\n","\n","# Entrenar un modelo de Gradient Boosting\n","gb_classifier = GradientBoostingClassifier(random_state=42)\n","gb_classifier.fit(xg2tr, yg2tr)\n","gb_predictions = gb_classifier.predict(xg2te)\n","\n","# Entrenar un modelo de XGBoost\n","xgb_classifier = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n","xgb_classifier.fit(xg2tr, yg2tr)\n","xgb_predictions = xgb_classifier.predict(xg2te)"]},{"cell_type":"code","execution_count":155,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1700761164949,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"Pz7SGoazOxhf","outputId":"9e0d2587-9976-4e11-ab08-322797c4e5e0"},"outputs":[{"data":{"text/plain":["{'Random Forest Accuracy': 0.847524440239672,\n"," 'AdaBoost Accuracy': 0.8649676758120467,\n"," 'Gradient Boosting Accuracy': 0.8650268054241564,\n"," 'XGBoost Accuracy': 0.864435509303059}"]},"execution_count":155,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluar el rendimiento de cada modelo\n","rf_accuracy = accuracy_score(yg2te, rf_predictions)\n","ada_accuracy = accuracy_score(yg2te, ada_predictions)\n","gb_accuracy = accuracy_score(yg2te, gb_predictions)\n","xgb_accuracy = accuracy_score(yg2te, xgb_predictions)\n","\n","# Mostrar la precisión de cada modelo\n","{'Random Forest Accuracy': rf_accuracy, 'AdaBoost Accuracy': ada_accuracy, 'Gradient Boosting Accuracy': gb_accuracy, 'XGBoost Accuracy': xgb_accuracy}"]},{"cell_type":"markdown","metadata":{},"source":["Aquí se puede ver que comparándolo con los atributos con 10% de ganancia, todos aumentaron un poco, excepto Random Forest, pero comparándolo con el modelo inicial, todos disminuyeron un poco."]},{"cell_type":"markdown","metadata":{"id":"Ma-4tbWlOxhg"},"source":["#### Árbol de clasificación"]},{"cell_type":"code","execution_count":156,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":630,"status":"ok","timestamp":1700761165570,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"GvS1bB4nOxhg","outputId":"553e9a13-1d4b-4aee-c107-79fd08b0b5ad"},"outputs":[{"name":"stdout","output_type":"stream","text":[" DecisionTreeClassifier Accuracy: 0.8163434247871334\n"]}],"source":["xg2tr, xg2te, yg2tr, yg2te = train_test_split(xg2, y, test_size = 0.2, random_state = 42)\n","\n","model = DecisionTreeClassifier()\n","model.fit(xg2tr, yg2tr)\n","yg2pr = model.predict(xg2te)\n","\n","accuracy = accuracy_score(yg2te, yg2pr)\n","print(\" DecisionTreeClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["Se obtuvo un resultado mayor al modelo inicial pero menor al anterior."]},{"cell_type":"markdown","metadata":{"id":"sPRW2i2wOxhh"},"source":["#### Clasificación con k-vecinos"]},{"cell_type":"code","execution_count":157,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9366,"status":"ok","timestamp":1700761174931,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"NLurSwYFOxhh","outputId":"73ffacd8-108e-4114-b069-fd4f30f19b3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["KNeighborsClassifier Accuracy: 0.8008908861557869\n"]}],"source":["xg2tr, xg2te, yg2tr, yg2te = train_test_split(xg2, y, test_size = 0.2, random_state = 42)\n","\n","xg2tr = np.ascontiguousarray(xg2tr)\n","xg2te = np.ascontiguousarray(xg2te)\n","\n","model = KNeighborsClassifier(n_neighbors=1)\n","model.fit(xg2tr, yg2tr)\n","yg2pr = model.predict(xg2te)\n","\n","accuracy = accuracy_score(yg2te, yg2pr)\n","print(\"KNeighborsClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["En este caso se mantuvo prácticamente igual, pero aun así es el menor de los anteriores."]},{"cell_type":"markdown","metadata":{"id":"wVWjhkELOxhi"},"source":["#### Redes neuronales"]},{"cell_type":"code","execution_count":158,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1700761175310,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"CzkgruChOxhi","outputId":"3b7ecabb-53de-4f87-913d-1c72fabb05e7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BMI</th>\n","      <th>Age</th>\n","      <th>Income</th>\n","      <th>HighBP_1</th>\n","      <th>PhysHlth</th>\n","      <th>GenHlth</th>\n","      <th>Education</th>\n","      <th>MentHlth</th>\n","      <th>Diabetes_binary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40</td>\n","      <td>9</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>15</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>18</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>25</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>30</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27</td>\n","      <td>11</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>253675</th>\n","      <td>45</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253676</th>\n","      <td>18</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>253677</th>\n","      <td>28</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253678</th>\n","      <td>23</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253679</th>\n","      <td>25</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>253680 rows × 9 columns</p>\n","</div>"],"text/plain":["        BMI  Age  Income  HighBP_1  PhysHlth  GenHlth  Education  MentHlth  \\\n","0        40    9       3         1        15        5          4        18   \n","1        25    7       1         0         0        3          6         0   \n","2        28    9       8         1        30        5          4        30   \n","3        27   11       6         1         0        2          3         0   \n","4        24   11       4         1         0        2          5         3   \n","...     ...  ...     ...       ...       ...      ...        ...       ...   \n","253675   45    5       7         1         5        3          6         0   \n","253676   18   11       4         1         0        4          2         0   \n","253677   28    2       2         0         0        1          5         0   \n","253678   23    7       1         1         0        3          5         0   \n","253679   25    9       2         1         0        2          6         0   \n","\n","        Diabetes_binary  \n","0                     0  \n","1                     0  \n","2                     0  \n","3                     0  \n","4                     0  \n","...                 ...  \n","253675                0  \n","253676                1  \n","253677                0  \n","253678                0  \n","253679                1  \n","\n","[253680 rows x 9 columns]"]},"execution_count":158,"metadata":{},"output_type":"execute_result"}],"source":["dg2 = xg2.copy()\n","dg2['Diabetes_binary'] = y.tolist()\n","dg2"]},{"cell_type":"code","execution_count":159,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1700761175310,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"tbQJOw6qOxhk"},"outputs":[],"source":["dg2 = dg2.sample(n = 10000, random_state = 42)\n","\n","traing2 = dg2.iloc[:8000,:]   #Equivale al 80% de los datos.\n","valg2 = dg2.iloc[8000:9000,:] #Equivale al 10% de los datos.\n","testg2 = dg2.iloc[9000:,:]    #Equivale al 10% de los datos."]},{"cell_type":"code","execution_count":160,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1700761175310,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"XTf7VJfVOxhk"},"outputs":[],"source":["traintg2 = MyDataset(traing2, 'Diabetes_binary')\n","testtg2 = MyDataset(testg2, 'Diabetes_binary')\n","valtg2 = MyDataset(valg2, 'Diabetes_binary')"]},{"cell_type":"code","execution_count":161,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1700761175311,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"mQsp5t9mOxhl"},"outputs":[],"source":["traindg2 = DataLoader(traintg2, batch_size = 2,\n","                            shuffle = False,\n","                            num_workers = 0,\n","                            collate_fn = None,\n","                            pin_memory = False,)\n","\n","testdg2 = DataLoader(testtg2, batch_size = 3,\n","                          shuffle = False,\n","                          num_workers = 0,\n","                          collate_fn = None,\n","                          pin_memory = False,)\n","\n","valdg2 = DataLoader(valtg2, batch_size = 3,\n","                        shuffle = False,\n","                        num_workers = 0,\n","                        collate_fn = None,\n","                        pin_memory = False,)"]},{"cell_type":"code","execution_count":162,"metadata":{"executionInfo":{"elapsed":193,"status":"ok","timestamp":1700761192032,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"DTa_aYKqOxhl"},"outputs":[],"source":["modelg2 = Net(num_inputs = 8, num_hidden = 3, num_outputs = 1)\n","\n","optimizerg2 = torch.optim.SGD(modelg2.parameters(), lr = 0.01)\n","criteriong2 = nn.MSELoss()"]},{"cell_type":"code","execution_count":163,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1700761193003,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"4lYqrs7-Oxhl","outputId":"35834b00-22a8-4497-e73e-1e3663421384"},"outputs":[{"data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=8, out_features=3, bias=True)\n","  (act_fn): Sigmoid()\n","  (fc2): Linear(in_features=3, out_features=1, bias=True)\n",")"]},"execution_count":163,"metadata":{},"output_type":"execute_result"}],"source":["modelg2.to(device)"]},{"cell_type":"code","execution_count":164,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30996,"status":"ok","timestamp":1700761224306,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"m9KXVZ1MOxhl","outputId":"30d49f67-11b8-4af0-e6e7-ad1342a1dea4"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Loss: 0.115271 \tValidation Loss: 0.121261\n","Validation loss decreased (inf --> 0.121261).  Saving model ...\n","Epoch: 1 \tTraining Loss: 0.110120 \tValidation Loss: 0.119707\n","Validation loss decreased (0.121261 --> 0.119707).  Saving model ...\n","Epoch: 2 \tTraining Loss: 0.109118 \tValidation Loss: 0.119591\n","Validation loss decreased (0.119707 --> 0.119591).  Saving model ...\n","Epoch: 3 \tTraining Loss: 0.108676 \tValidation Loss: 0.119644\n","Epoch: 4 \tTraining Loss: 0.108346 \tValidation Loss: 0.119738\n","Epoch: 5 \tTraining Loss: 0.108077 \tValidation Loss: 0.119857\n","Epoch: 6 \tTraining Loss: 0.107849 \tValidation Loss: 0.119988\n","Epoch: 7 \tTraining Loss: 0.107649 \tValidation Loss: 0.120118\n","Epoch: 8 \tTraining Loss: 0.107470 \tValidation Loss: 0.120238\n","Epoch: 9 \tTraining Loss: 0.107308 \tValidation Loss: 0.120347\n","Epoch: 10 \tTraining Loss: 0.107161 \tValidation Loss: 0.120445\n","Epoch: 11 \tTraining Loss: 0.107026 \tValidation Loss: 0.120533\n","Epoch: 12 \tTraining Loss: 0.106900 \tValidation Loss: 0.120614\n","Epoch: 13 \tTraining Loss: 0.106784 \tValidation Loss: 0.120688\n","Epoch: 14 \tTraining Loss: 0.106675 \tValidation Loss: 0.120757\n","Epoch: 15 \tTraining Loss: 0.106573 \tValidation Loss: 0.120821\n","Epoch: 16 \tTraining Loss: 0.106476 \tValidation Loss: 0.120882\n","Epoch: 17 \tTraining Loss: 0.106385 \tValidation Loss: 0.120940\n","Epoch: 18 \tTraining Loss: 0.106298 \tValidation Loss: 0.120998\n","Epoch: 19 \tTraining Loss: 0.106215 \tValidation Loss: 0.121055\n","Epoch: 20 \tTraining Loss: 0.106136 \tValidation Loss: 0.121112\n","Epoch: 21 \tTraining Loss: 0.106060 \tValidation Loss: 0.121168\n","Epoch: 22 \tTraining Loss: 0.105987 \tValidation Loss: 0.121224\n","Epoch: 23 \tTraining Loss: 0.105916 \tValidation Loss: 0.121279\n","Epoch: 24 \tTraining Loss: 0.105848 \tValidation Loss: 0.121332\n","Epoch: 25 \tTraining Loss: 0.105782 \tValidation Loss: 0.121385\n","Epoch: 26 \tTraining Loss: 0.105718 \tValidation Loss: 0.121436\n","Epoch: 27 \tTraining Loss: 0.105657 \tValidation Loss: 0.121485\n","Epoch: 28 \tTraining Loss: 0.105598 \tValidation Loss: 0.121532\n","Epoch: 29 \tTraining Loss: 0.105540 \tValidation Loss: 0.121577\n","Epoch: 30 \tTraining Loss: 0.105485 \tValidation Loss: 0.121620\n","Epoch: 31 \tTraining Loss: 0.105432 \tValidation Loss: 0.121661\n","Epoch: 32 \tTraining Loss: 0.105380 \tValidation Loss: 0.121699\n","Epoch: 33 \tTraining Loss: 0.105330 \tValidation Loss: 0.121736\n","Epoch: 34 \tTraining Loss: 0.105282 \tValidation Loss: 0.121770\n","Epoch: 35 \tTraining Loss: 0.105235 \tValidation Loss: 0.121802\n","Epoch: 36 \tTraining Loss: 0.105190 \tValidation Loss: 0.121833\n","Epoch: 37 \tTraining Loss: 0.105146 \tValidation Loss: 0.121863\n","Epoch: 38 \tTraining Loss: 0.105104 \tValidation Loss: 0.121890\n","Epoch: 39 \tTraining Loss: 0.105063 \tValidation Loss: 0.121916\n","Epoch: 40 \tTraining Loss: 0.105024 \tValidation Loss: 0.121941\n","Epoch: 41 \tTraining Loss: 0.104986 \tValidation Loss: 0.121964\n","Epoch: 42 \tTraining Loss: 0.104949 \tValidation Loss: 0.121986\n","Epoch: 43 \tTraining Loss: 0.104913 \tValidation Loss: 0.122006\n","Epoch: 44 \tTraining Loss: 0.104879 \tValidation Loss: 0.122025\n","Epoch: 45 \tTraining Loss: 0.104845 \tValidation Loss: 0.122042\n","Epoch: 46 \tTraining Loss: 0.104813 \tValidation Loss: 0.122058\n","Epoch: 47 \tTraining Loss: 0.104782 \tValidation Loss: 0.122072\n","Epoch: 48 \tTraining Loss: 0.104752 \tValidation Loss: 0.122085\n","Epoch: 49 \tTraining Loss: 0.104723 \tValidation Loss: 0.122097\n","Epoch: 50 \tTraining Loss: 0.104695 \tValidation Loss: 0.122108\n","Epoch: 51 \tTraining Loss: 0.104667 \tValidation Loss: 0.122117\n","Epoch: 52 \tTraining Loss: 0.104641 \tValidation Loss: 0.122126\n","Epoch: 53 \tTraining Loss: 0.104615 \tValidation Loss: 0.122133\n","Epoch: 54 \tTraining Loss: 0.104590 \tValidation Loss: 0.122140\n","Epoch: 55 \tTraining Loss: 0.104565 \tValidation Loss: 0.122146\n","Epoch: 56 \tTraining Loss: 0.104542 \tValidation Loss: 0.122151\n","Epoch: 57 \tTraining Loss: 0.104519 \tValidation Loss: 0.122156\n","Epoch: 58 \tTraining Loss: 0.104496 \tValidation Loss: 0.122160\n","Epoch: 59 \tTraining Loss: 0.104475 \tValidation Loss: 0.122164\n","Epoch: 60 \tTraining Loss: 0.104453 \tValidation Loss: 0.122168\n","Epoch: 61 \tTraining Loss: 0.104433 \tValidation Loss: 0.122171\n","Epoch: 62 \tTraining Loss: 0.104413 \tValidation Loss: 0.122174\n","Epoch: 63 \tTraining Loss: 0.104393 \tValidation Loss: 0.122176\n","Epoch: 64 \tTraining Loss: 0.104374 \tValidation Loss: 0.122179\n","Epoch: 65 \tTraining Loss: 0.104355 \tValidation Loss: 0.122181\n","Epoch: 66 \tTraining Loss: 0.104337 \tValidation Loss: 0.122183\n","Epoch: 67 \tTraining Loss: 0.104320 \tValidation Loss: 0.122185\n","Epoch: 68 \tTraining Loss: 0.104302 \tValidation Loss: 0.122188\n","Epoch: 69 \tTraining Loss: 0.104286 \tValidation Loss: 0.122190\n","Epoch: 70 \tTraining Loss: 0.104269 \tValidation Loss: 0.122192\n","Epoch: 71 \tTraining Loss: 0.104253 \tValidation Loss: 0.122194\n","Epoch: 72 \tTraining Loss: 0.104238 \tValidation Loss: 0.122196\n","Epoch: 73 \tTraining Loss: 0.104222 \tValidation Loss: 0.122198\n","Epoch: 74 \tTraining Loss: 0.104207 \tValidation Loss: 0.122199\n","Epoch: 75 \tTraining Loss: 0.104193 \tValidation Loss: 0.122201\n","Epoch: 76 \tTraining Loss: 0.104179 \tValidation Loss: 0.122204\n","Epoch: 77 \tTraining Loss: 0.104165 \tValidation Loss: 0.122206\n","Epoch: 78 \tTraining Loss: 0.104151 \tValidation Loss: 0.122208\n","Epoch: 79 \tTraining Loss: 0.104138 \tValidation Loss: 0.122210\n","Epoch: 80 \tTraining Loss: 0.104125 \tValidation Loss: 0.122212\n","Epoch: 81 \tTraining Loss: 0.104112 \tValidation Loss: 0.122214\n","Epoch: 82 \tTraining Loss: 0.104100 \tValidation Loss: 0.122216\n","Epoch: 83 \tTraining Loss: 0.104088 \tValidation Loss: 0.122219\n","Epoch: 84 \tTraining Loss: 0.104076 \tValidation Loss: 0.122221\n","Epoch: 85 \tTraining Loss: 0.104064 \tValidation Loss: 0.122223\n","Epoch: 86 \tTraining Loss: 0.104053 \tValidation Loss: 0.122226\n","Epoch: 87 \tTraining Loss: 0.104041 \tValidation Loss: 0.122228\n","Epoch: 88 \tTraining Loss: 0.104030 \tValidation Loss: 0.122230\n","Epoch: 89 \tTraining Loss: 0.104020 \tValidation Loss: 0.122233\n","Epoch: 90 \tTraining Loss: 0.104009 \tValidation Loss: 0.122235\n","Epoch: 91 \tTraining Loss: 0.103999 \tValidation Loss: 0.122238\n","Epoch: 92 \tTraining Loss: 0.103989 \tValidation Loss: 0.122240\n","Epoch: 93 \tTraining Loss: 0.103979 \tValidation Loss: 0.122243\n","Epoch: 94 \tTraining Loss: 0.103969 \tValidation Loss: 0.122245\n","Epoch: 95 \tTraining Loss: 0.103959 \tValidation Loss: 0.122248\n","Epoch: 96 \tTraining Loss: 0.103950 \tValidation Loss: 0.122250\n","Epoch: 97 \tTraining Loss: 0.103941 \tValidation Loss: 0.122253\n","Epoch: 98 \tTraining Loss: 0.103932 \tValidation Loss: 0.122255\n","Epoch: 99 \tTraining Loss: 0.103923 \tValidation Loss: 0.122257\n"]}],"source":["train_model(modelg2, optimizerg2, criteriong2, traindg2, valdg2, num_epochs = 100)"]},{"cell_type":"code","execution_count":165,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1700761224307,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"NaRG0IkBOxhl","outputId":"d8d0bfe8-eedc-4a65-8170-0f75d4fecaf8"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":165,"metadata":{},"output_type":"execute_result"}],"source":["modelg2.load_state_dict(torch.load('diabetesmodel.pt'))"]},{"cell_type":"code","execution_count":166,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1700761224684,"user":{"displayName":"alejandro vega","userId":"10932941274580883322"},"user_tz":300},"id":"bJd42QdROxhn","outputId":"fea3adca-a0f1-4ced-baff-2165a6d72470"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model: 13.70%\n"]}],"source":["print(f\"Accuracy of the model: {100.0*eval_model(modelg2, testdg2):4.2f}%\")"]},{"cell_type":"markdown","metadata":{},"source":["Se mantuvo igual que en los anteriores."]},{"cell_type":"markdown","metadata":{"id":"QNlJ7SrzRRg-"},"source":["## Normalización"]},{"cell_type":"markdown","metadata":{},"source":["Ahora, se normalizan los datos del dataset inicial, excepto la variable objetivo."]},{"cell_type":"code","execution_count":167,"metadata":{"id":"86g2h3wdRUNV"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BMI</th>\n","      <th>GenHlth</th>\n","      <th>MentHlth</th>\n","      <th>PhysHlth</th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Income</th>\n","      <th>HighBP_1</th>\n","      <th>HighChol_1</th>\n","      <th>CholCheck_1</th>\n","      <th>...</th>\n","      <th>Stroke_1</th>\n","      <th>HeartDiseaseorAttack_1</th>\n","      <th>PhysActivity_1</th>\n","      <th>Fruits_1</th>\n","      <th>Veggies_1</th>\n","      <th>HvyAlcoholConsump_1</th>\n","      <th>AnyHealthcare_1</th>\n","      <th>NoDocbcCost_1</th>\n","      <th>DiffWalk_1</th>\n","      <th>Sex_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.757936</td>\n","      <td>2.329121</td>\n","      <td>1.998592</td>\n","      <td>1.233999</td>\n","      <td>0.316900</td>\n","      <td>-1.065595</td>\n","      <td>-1.474487</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.205637</td>\n","      <td>-0.322458</td>\n","      <td>-1.762814</td>\n","      <td>-1.316872</td>\n","      <td>0.482087</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>2.223615</td>\n","      <td>-0.887021</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.511806</td>\n","      <td>0.457294</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>-0.337933</td>\n","      <td>0.963272</td>\n","      <td>-2.440138</td>\n","      <td>-0.866785</td>\n","      <td>-0.858182</td>\n","      <td>-5.078164</td>\n","      <td>...</td>\n","      <td>-0.205637</td>\n","      <td>-0.322458</td>\n","      <td>0.567275</td>\n","      <td>-1.316872</td>\n","      <td>-2.074316</td>\n","      <td>-0.244014</td>\n","      <td>-4.407954</td>\n","      <td>3.298445</td>\n","      <td>-0.449718</td>\n","      <td>-0.887021</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.057858</td>\n","      <td>2.329121</td>\n","      <td>3.617407</td>\n","      <td>2.954590</td>\n","      <td>0.316900</td>\n","      <td>-1.065595</td>\n","      <td>0.939638</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.205637</td>\n","      <td>-0.322458</td>\n","      <td>-1.762814</td>\n","      <td>0.759375</td>\n","      <td>-2.074316</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>3.298445</td>\n","      <td>2.223615</td>\n","      <td>-0.887021</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.209174</td>\n","      <td>-0.478619</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>0.971733</td>\n","      <td>-2.080028</td>\n","      <td>-0.026012</td>\n","      <td>1.153688</td>\n","      <td>-0.858182</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.205637</td>\n","      <td>-0.322458</td>\n","      <td>0.567275</td>\n","      <td>0.759375</td>\n","      <td>0.482087</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>-0.887021</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.663122</td>\n","      <td>-0.478619</td>\n","      <td>-0.024926</td>\n","      <td>-0.486592</td>\n","      <td>0.971733</td>\n","      <td>-0.051162</td>\n","      <td>-0.991662</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.205637</td>\n","      <td>-0.322458</td>\n","      <td>0.567275</td>\n","      <td>0.759375</td>\n","      <td>0.482087</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>-0.887021</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>253675</th>\n","      <td>2.514516</td>\n","      <td>0.457294</td>\n","      <td>-0.429630</td>\n","      <td>0.086938</td>\n","      <td>-0.992766</td>\n","      <td>0.963272</td>\n","      <td>0.456813</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.205637</td>\n","      <td>-0.322458</td>\n","      <td>-1.762814</td>\n","      <td>0.759375</td>\n","      <td>0.482087</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>1.127369</td>\n","    </tr>\n","    <tr>\n","      <th>253676</th>\n","      <td>-1.571019</td>\n","      <td>1.393207</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>0.971733</td>\n","      <td>-3.094461</td>\n","      <td>-0.991662</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.205637</td>\n","      <td>-0.322458</td>\n","      <td>-1.762814</td>\n","      <td>-1.316872</td>\n","      <td>-2.074316</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>2.223615</td>\n","      <td>-0.887021</td>\n","    </tr>\n","    <tr>\n","      <th>253677</th>\n","      <td>-0.057858</td>\n","      <td>-1.414532</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>-1.975015</td>\n","      <td>-0.051162</td>\n","      <td>-1.957312</td>\n","      <td>-0.866785</td>\n","      <td>-0.858182</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.205637</td>\n","      <td>-0.322458</td>\n","      <td>0.567275</td>\n","      <td>0.759375</td>\n","      <td>-2.074316</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>-0.887021</td>\n","    </tr>\n","    <tr>\n","      <th>253678</th>\n","      <td>-0.814438</td>\n","      <td>0.457294</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>-0.337933</td>\n","      <td>-0.051162</td>\n","      <td>-2.440138</td>\n","      <td>1.153688</td>\n","      <td>-0.858182</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.205637</td>\n","      <td>-0.322458</td>\n","      <td>-1.762814</td>\n","      <td>0.759375</td>\n","      <td>0.482087</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>1.127369</td>\n","    </tr>\n","    <tr>\n","      <th>253679</th>\n","      <td>-0.511806</td>\n","      <td>-0.478619</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>0.316900</td>\n","      <td>0.963272</td>\n","      <td>-1.957312</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.205637</td>\n","      <td>3.101183</td>\n","      <td>0.567275</td>\n","      <td>0.759375</td>\n","      <td>-2.074316</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>-0.887021</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>253680 rows × 21 columns</p>\n","</div>"],"text/plain":["             BMI   GenHlth  MentHlth  PhysHlth       Age  Education    Income  \\\n","0       1.757936  2.329121  1.998592  1.233999  0.316900  -1.065595 -1.474487   \n","1      -0.511806  0.457294 -0.429630 -0.486592 -0.337933   0.963272 -2.440138   \n","2      -0.057858  2.329121  3.617407  2.954590  0.316900  -1.065595  0.939638   \n","3      -0.209174 -0.478619 -0.429630 -0.486592  0.971733  -2.080028 -0.026012   \n","4      -0.663122 -0.478619 -0.024926 -0.486592  0.971733  -0.051162 -0.991662   \n","...          ...       ...       ...       ...       ...        ...       ...   \n","253675  2.514516  0.457294 -0.429630  0.086938 -0.992766   0.963272  0.456813   \n","253676 -1.571019  1.393207 -0.429630 -0.486592  0.971733  -3.094461 -0.991662   \n","253677 -0.057858 -1.414532 -0.429630 -0.486592 -1.975015  -0.051162 -1.957312   \n","253678 -0.814438  0.457294 -0.429630 -0.486592 -0.337933  -0.051162 -2.440138   \n","253679 -0.511806 -0.478619 -0.429630 -0.486592  0.316900   0.963272 -1.957312   \n","\n","        HighBP_1  HighChol_1  CholCheck_1  ...  Stroke_1  \\\n","0       1.153688    1.165254     0.196922  ... -0.205637   \n","1      -0.866785   -0.858182    -5.078164  ... -0.205637   \n","2       1.153688    1.165254     0.196922  ... -0.205637   \n","3       1.153688   -0.858182     0.196922  ... -0.205637   \n","4       1.153688    1.165254     0.196922  ... -0.205637   \n","...          ...         ...          ...  ...       ...   \n","253675  1.153688    1.165254     0.196922  ... -0.205637   \n","253676  1.153688    1.165254     0.196922  ... -0.205637   \n","253677 -0.866785   -0.858182     0.196922  ... -0.205637   \n","253678  1.153688   -0.858182     0.196922  ... -0.205637   \n","253679  1.153688    1.165254     0.196922  ... -0.205637   \n","\n","        HeartDiseaseorAttack_1  PhysActivity_1  Fruits_1  Veggies_1  \\\n","0                    -0.322458       -1.762814 -1.316872   0.482087   \n","1                    -0.322458        0.567275 -1.316872  -2.074316   \n","2                    -0.322458       -1.762814  0.759375  -2.074316   \n","3                    -0.322458        0.567275  0.759375   0.482087   \n","4                    -0.322458        0.567275  0.759375   0.482087   \n","...                        ...             ...       ...        ...   \n","253675               -0.322458       -1.762814  0.759375   0.482087   \n","253676               -0.322458       -1.762814 -1.316872  -2.074316   \n","253677               -0.322458        0.567275  0.759375  -2.074316   \n","253678               -0.322458       -1.762814  0.759375   0.482087   \n","253679                3.101183        0.567275  0.759375  -2.074316   \n","\n","        HvyAlcoholConsump_1  AnyHealthcare_1  NoDocbcCost_1  DiffWalk_1  \\\n","0                 -0.244014         0.226863      -0.303173    2.223615   \n","1                 -0.244014        -4.407954       3.298445   -0.449718   \n","2                 -0.244014         0.226863       3.298445    2.223615   \n","3                 -0.244014         0.226863      -0.303173   -0.449718   \n","4                 -0.244014         0.226863      -0.303173   -0.449718   \n","...                     ...              ...            ...         ...   \n","253675            -0.244014         0.226863      -0.303173   -0.449718   \n","253676            -0.244014         0.226863      -0.303173    2.223615   \n","253677            -0.244014         0.226863      -0.303173   -0.449718   \n","253678            -0.244014         0.226863      -0.303173   -0.449718   \n","253679            -0.244014         0.226863      -0.303173   -0.449718   \n","\n","           Sex_1  \n","0      -0.887021  \n","1      -0.887021  \n","2      -0.887021  \n","3      -0.887021  \n","4      -0.887021  \n","...          ...  \n","253675  1.127369  \n","253676 -0.887021  \n","253677 -0.887021  \n","253678  1.127369  \n","253679 -0.887021  \n","\n","[253680 rows x 21 columns]"]},"execution_count":167,"metadata":{},"output_type":"execute_result"}],"source":["xn = x.copy()\n","columns = xn.columns.values\n","\n","for i in columns:\n","    mean = np.mean(xn[i])           #Normalizar los datos cogiendo cada columna, restando\n","    std = np.std(xn[i])             #la media de esa columna y diviviendo por su\n","    xn[i] = (xn[i] - mean) / std    #desviacion estandar\n","\n","xn"]},{"cell_type":"markdown","metadata":{},"source":["#### Algoritmos de ensamble"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[],"source":["xntr, xnte, yntr, ynte = train_test_split(xn, y, test_size = 0.2, random_state = 42)\n","\n","# Entrenar un modelo de Random Forest\n","rf_classifier = RandomForestClassifier(random_state=42)\n","rf_classifier.fit(xntr, yntr)\n","rf_predictions = rf_classifier.predict(xnte)\n","\n","# Entrenar un modelo de AdaBoost\n","ada_classifier = AdaBoostClassifier(random_state=42)\n","ada_classifier.fit(xntr, yntr)\n","ada_predictions = ada_classifier.predict(xnte)\n","\n","# Entrenar un modelo de Gradient Boosting\n","gb_classifier = GradientBoostingClassifier(random_state=42)\n","gb_classifier.fit(xntr, yntr)\n","gb_predictions = gb_classifier.predict(xnte)\n","\n","# Entrenar un modelo de XGBoost\n","xgb_classifier = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n","xgb_classifier.fit(xntr, yntr)\n","xgb_predictions = xgb_classifier.predict(xnte)"]},{"cell_type":"code","execution_count":169,"metadata":{},"outputs":[{"data":{"text/plain":["{'Random Forest Accuracy': 0.8599219489120151,\n"," 'AdaBoost Accuracy': 0.8664262062440871,\n"," 'Gradient Boosting Accuracy': 0.8675102491327656,\n"," 'XGBoost Accuracy': 0.8667612740460423}"]},"execution_count":169,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluar el rendimiento de cada modelo\n","rf_accuracy = accuracy_score(ynte, rf_predictions)\n","ada_accuracy = accuracy_score(ynte, ada_predictions)\n","gb_accuracy = accuracy_score(ynte, gb_predictions)\n","xgb_accuracy = accuracy_score(ynte, xgb_predictions)\n","\n","# Mostrar la precisión de cada modelo\n","{'Random Forest Accuracy': rf_accuracy, 'AdaBoost Accuracy': ada_accuracy, 'Gradient Boosting Accuracy': gb_accuracy, 'XGBoost Accuracy': xgb_accuracy}"]},{"cell_type":"markdown","metadata":{},"source":["Como se puede ver, se obtuvo el mismo accuracy que con el modelo inicial."]},{"cell_type":"markdown","metadata":{},"source":["#### Árbol de clasificación"]},{"cell_type":"code","execution_count":170,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" DecisionTreeClassifier Accuracy: 0.7975796278776411\n"]}],"source":["xntr, xnte, yntr, ynte = train_test_split(xn, y, test_size = 0.2, random_state = 42)\n","\n","model = DecisionTreeClassifier()\n","model.fit(xntr, yntr)\n","ynpr = model.predict(xnte)\n","\n","accuracy = accuracy_score(ynte, ynpr)\n","print(\" DecisionTreeClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["Aquí se obtuvo prácticamente lo mismo que en el modelo inicial, pero cambio de 79.6% a 79.7%."]},{"cell_type":"markdown","metadata":{},"source":["#### Clasificación con k-vecinos"]},{"cell_type":"code","execution_count":171,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["KNeighborsClassifier Accuracy: 0.8031378114159571\n"]}],"source":["xntr, xnte, yntr, ynte = train_test_split(xn, y, test_size = 0.2, random_state = 42)\n","\n","xntr = np.ascontiguousarray(xntr)\n","xnte = np.ascontiguousarray(xnte)\n","\n","model = KNeighborsClassifier(n_neighbors=1)\n","model.fit(xntr, yntr)\n","ynpr = model.predict(xnte)\n","\n","accuracy = accuracy_score(ynte, ynpr)\n","print(\"KNeighborsClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["Igual que para el árbol de clasificación, cambio de 80.5% en el modelo inicial a 80.3%."]},{"cell_type":"markdown","metadata":{},"source":["#### Redes neuronales"]},{"cell_type":"code","execution_count":172,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BMI</th>\n","      <th>GenHlth</th>\n","      <th>MentHlth</th>\n","      <th>PhysHlth</th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Income</th>\n","      <th>HighBP_1</th>\n","      <th>HighChol_1</th>\n","      <th>CholCheck_1</th>\n","      <th>...</th>\n","      <th>HeartDiseaseorAttack_1</th>\n","      <th>PhysActivity_1</th>\n","      <th>Fruits_1</th>\n","      <th>Veggies_1</th>\n","      <th>HvyAlcoholConsump_1</th>\n","      <th>AnyHealthcare_1</th>\n","      <th>NoDocbcCost_1</th>\n","      <th>DiffWalk_1</th>\n","      <th>Sex_1</th>\n","      <th>Diabetes_binary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.757936</td>\n","      <td>2.329121</td>\n","      <td>1.998592</td>\n","      <td>1.233999</td>\n","      <td>0.316900</td>\n","      <td>-1.065595</td>\n","      <td>-1.474487</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.322458</td>\n","      <td>-1.762814</td>\n","      <td>-1.316872</td>\n","      <td>0.482087</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>2.223615</td>\n","      <td>-0.887021</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.511806</td>\n","      <td>0.457294</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>-0.337933</td>\n","      <td>0.963272</td>\n","      <td>-2.440138</td>\n","      <td>-0.866785</td>\n","      <td>-0.858182</td>\n","      <td>-5.078164</td>\n","      <td>...</td>\n","      <td>-0.322458</td>\n","      <td>0.567275</td>\n","      <td>-1.316872</td>\n","      <td>-2.074316</td>\n","      <td>-0.244014</td>\n","      <td>-4.407954</td>\n","      <td>3.298445</td>\n","      <td>-0.449718</td>\n","      <td>-0.887021</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.057858</td>\n","      <td>2.329121</td>\n","      <td>3.617407</td>\n","      <td>2.954590</td>\n","      <td>0.316900</td>\n","      <td>-1.065595</td>\n","      <td>0.939638</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.322458</td>\n","      <td>-1.762814</td>\n","      <td>0.759375</td>\n","      <td>-2.074316</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>3.298445</td>\n","      <td>2.223615</td>\n","      <td>-0.887021</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.209174</td>\n","      <td>-0.478619</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>0.971733</td>\n","      <td>-2.080028</td>\n","      <td>-0.026012</td>\n","      <td>1.153688</td>\n","      <td>-0.858182</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.322458</td>\n","      <td>0.567275</td>\n","      <td>0.759375</td>\n","      <td>0.482087</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>-0.887021</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.663122</td>\n","      <td>-0.478619</td>\n","      <td>-0.024926</td>\n","      <td>-0.486592</td>\n","      <td>0.971733</td>\n","      <td>-0.051162</td>\n","      <td>-0.991662</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.322458</td>\n","      <td>0.567275</td>\n","      <td>0.759375</td>\n","      <td>0.482087</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>-0.887021</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>253675</th>\n","      <td>2.514516</td>\n","      <td>0.457294</td>\n","      <td>-0.429630</td>\n","      <td>0.086938</td>\n","      <td>-0.992766</td>\n","      <td>0.963272</td>\n","      <td>0.456813</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.322458</td>\n","      <td>-1.762814</td>\n","      <td>0.759375</td>\n","      <td>0.482087</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>1.127369</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253676</th>\n","      <td>-1.571019</td>\n","      <td>1.393207</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>0.971733</td>\n","      <td>-3.094461</td>\n","      <td>-0.991662</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.322458</td>\n","      <td>-1.762814</td>\n","      <td>-1.316872</td>\n","      <td>-2.074316</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>2.223615</td>\n","      <td>-0.887021</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>253677</th>\n","      <td>-0.057858</td>\n","      <td>-1.414532</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>-1.975015</td>\n","      <td>-0.051162</td>\n","      <td>-1.957312</td>\n","      <td>-0.866785</td>\n","      <td>-0.858182</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.322458</td>\n","      <td>0.567275</td>\n","      <td>0.759375</td>\n","      <td>-2.074316</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>-0.887021</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253678</th>\n","      <td>-0.814438</td>\n","      <td>0.457294</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>-0.337933</td>\n","      <td>-0.051162</td>\n","      <td>-2.440138</td>\n","      <td>1.153688</td>\n","      <td>-0.858182</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>-0.322458</td>\n","      <td>-1.762814</td>\n","      <td>0.759375</td>\n","      <td>0.482087</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>1.127369</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253679</th>\n","      <td>-0.511806</td>\n","      <td>-0.478619</td>\n","      <td>-0.429630</td>\n","      <td>-0.486592</td>\n","      <td>0.316900</td>\n","      <td>0.963272</td>\n","      <td>-1.957312</td>\n","      <td>1.153688</td>\n","      <td>1.165254</td>\n","      <td>0.196922</td>\n","      <td>...</td>\n","      <td>3.101183</td>\n","      <td>0.567275</td>\n","      <td>0.759375</td>\n","      <td>-2.074316</td>\n","      <td>-0.244014</td>\n","      <td>0.226863</td>\n","      <td>-0.303173</td>\n","      <td>-0.449718</td>\n","      <td>-0.887021</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>253680 rows × 22 columns</p>\n","</div>"],"text/plain":["             BMI   GenHlth  MentHlth  PhysHlth       Age  Education    Income  \\\n","0       1.757936  2.329121  1.998592  1.233999  0.316900  -1.065595 -1.474487   \n","1      -0.511806  0.457294 -0.429630 -0.486592 -0.337933   0.963272 -2.440138   \n","2      -0.057858  2.329121  3.617407  2.954590  0.316900  -1.065595  0.939638   \n","3      -0.209174 -0.478619 -0.429630 -0.486592  0.971733  -2.080028 -0.026012   \n","4      -0.663122 -0.478619 -0.024926 -0.486592  0.971733  -0.051162 -0.991662   \n","...          ...       ...       ...       ...       ...        ...       ...   \n","253675  2.514516  0.457294 -0.429630  0.086938 -0.992766   0.963272  0.456813   \n","253676 -1.571019  1.393207 -0.429630 -0.486592  0.971733  -3.094461 -0.991662   \n","253677 -0.057858 -1.414532 -0.429630 -0.486592 -1.975015  -0.051162 -1.957312   \n","253678 -0.814438  0.457294 -0.429630 -0.486592 -0.337933  -0.051162 -2.440138   \n","253679 -0.511806 -0.478619 -0.429630 -0.486592  0.316900   0.963272 -1.957312   \n","\n","        HighBP_1  HighChol_1  CholCheck_1  ...  HeartDiseaseorAttack_1  \\\n","0       1.153688    1.165254     0.196922  ...               -0.322458   \n","1      -0.866785   -0.858182    -5.078164  ...               -0.322458   \n","2       1.153688    1.165254     0.196922  ...               -0.322458   \n","3       1.153688   -0.858182     0.196922  ...               -0.322458   \n","4       1.153688    1.165254     0.196922  ...               -0.322458   \n","...          ...         ...          ...  ...                     ...   \n","253675  1.153688    1.165254     0.196922  ...               -0.322458   \n","253676  1.153688    1.165254     0.196922  ...               -0.322458   \n","253677 -0.866785   -0.858182     0.196922  ...               -0.322458   \n","253678  1.153688   -0.858182     0.196922  ...               -0.322458   \n","253679  1.153688    1.165254     0.196922  ...                3.101183   \n","\n","        PhysActivity_1  Fruits_1  Veggies_1  HvyAlcoholConsump_1  \\\n","0            -1.762814 -1.316872   0.482087            -0.244014   \n","1             0.567275 -1.316872  -2.074316            -0.244014   \n","2            -1.762814  0.759375  -2.074316            -0.244014   \n","3             0.567275  0.759375   0.482087            -0.244014   \n","4             0.567275  0.759375   0.482087            -0.244014   \n","...                ...       ...        ...                  ...   \n","253675       -1.762814  0.759375   0.482087            -0.244014   \n","253676       -1.762814 -1.316872  -2.074316            -0.244014   \n","253677        0.567275  0.759375  -2.074316            -0.244014   \n","253678       -1.762814  0.759375   0.482087            -0.244014   \n","253679        0.567275  0.759375  -2.074316            -0.244014   \n","\n","        AnyHealthcare_1  NoDocbcCost_1  DiffWalk_1     Sex_1  Diabetes_binary  \n","0              0.226863      -0.303173    2.223615 -0.887021                0  \n","1             -4.407954       3.298445   -0.449718 -0.887021                0  \n","2              0.226863       3.298445    2.223615 -0.887021                0  \n","3              0.226863      -0.303173   -0.449718 -0.887021                0  \n","4              0.226863      -0.303173   -0.449718 -0.887021                0  \n","...                 ...            ...         ...       ...              ...  \n","253675         0.226863      -0.303173   -0.449718  1.127369                0  \n","253676         0.226863      -0.303173    2.223615 -0.887021                1  \n","253677         0.226863      -0.303173   -0.449718 -0.887021                0  \n","253678         0.226863      -0.303173   -0.449718  1.127369                0  \n","253679         0.226863      -0.303173   -0.449718 -0.887021                1  \n","\n","[253680 rows x 22 columns]"]},"execution_count":172,"metadata":{},"output_type":"execute_result"}],"source":["dn = xn.copy()\n","dn['Diabetes_binary'] = y.tolist()\n","dn"]},{"cell_type":"code","execution_count":173,"metadata":{},"outputs":[],"source":["dn = dn.sample(n = 10000, random_state = 42)\n","\n","trainn = dn.iloc[:8000,:]   #Equivale al 80% de los datos.\n","valn = dn.iloc[8000:9000,:] #Equivale al 10% de los datos.\n","testn = dn.iloc[9000:,:]    #Equivale al 10% de los datos."]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[],"source":["traintn = MyDataset(trainn, 'Diabetes_binary')\n","testtn = MyDataset(testn, 'Diabetes_binary')\n","valtn = MyDataset(valn, 'Diabetes_binary')"]},{"cell_type":"code","execution_count":175,"metadata":{},"outputs":[],"source":["traindn = DataLoader(traintn, batch_size = 2,\n","                            shuffle = False,\n","                            num_workers = 0,\n","                            collate_fn = None,\n","                            pin_memory = False,)\n","\n","testdn = DataLoader(testtn, batch_size = 3,\n","                          shuffle = False,\n","                          num_workers = 0,\n","                          collate_fn = None,\n","                          pin_memory = False,)\n","\n","valdn = DataLoader(valtn, batch_size = 3,\n","                        shuffle = False,\n","                        num_workers = 0,\n","                        collate_fn = None,\n","                        pin_memory = False,)"]},{"cell_type":"code","execution_count":176,"metadata":{},"outputs":[],"source":["modeln = Net(num_inputs = 21, num_hidden = 3, num_outputs = 1)\n","\n","optimizern = torch.optim.SGD(modeln.parameters(), lr = 0.01)\n","criterionn = nn.MSELoss()"]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[{"data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=21, out_features=3, bias=True)\n","  (act_fn): Sigmoid()\n","  (fc2): Linear(in_features=3, out_features=1, bias=True)\n",")"]},"execution_count":177,"metadata":{},"output_type":"execute_result"}],"source":["modeln.to(device)"]},{"cell_type":"code","execution_count":178,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Loss: 0.103764 \tValidation Loss: 0.123648\n","Validation loss decreased (inf --> 0.123648).  Saving model ...\n","Epoch: 1 \tTraining Loss: 0.099529 \tValidation Loss: 0.124128\n","Epoch: 2 \tTraining Loss: 0.099190 \tValidation Loss: 0.124245\n","Epoch: 3 \tTraining Loss: 0.099029 \tValidation Loss: 0.124306\n","Epoch: 4 \tTraining Loss: 0.098887 \tValidation Loss: 0.124353\n","Epoch: 5 \tTraining Loss: 0.098752 \tValidation Loss: 0.124392\n","Epoch: 6 \tTraining Loss: 0.098621 \tValidation Loss: 0.124423\n","Epoch: 7 \tTraining Loss: 0.098497 \tValidation Loss: 0.124449\n","Epoch: 8 \tTraining Loss: 0.098379 \tValidation Loss: 0.124470\n","Epoch: 9 \tTraining Loss: 0.098268 \tValidation Loss: 0.124487\n","Epoch: 10 \tTraining Loss: 0.098166 \tValidation Loss: 0.124501\n","Epoch: 11 \tTraining Loss: 0.098071 \tValidation Loss: 0.124512\n","Epoch: 12 \tTraining Loss: 0.097985 \tValidation Loss: 0.124519\n","Epoch: 13 \tTraining Loss: 0.097907 \tValidation Loss: 0.124524\n","Epoch: 14 \tTraining Loss: 0.097837 \tValidation Loss: 0.124527\n","Epoch: 15 \tTraining Loss: 0.097774 \tValidation Loss: 0.124528\n","Epoch: 16 \tTraining Loss: 0.097717 \tValidation Loss: 0.124526\n","Epoch: 17 \tTraining Loss: 0.097667 \tValidation Loss: 0.124522\n","Epoch: 18 \tTraining Loss: 0.097622 \tValidation Loss: 0.124517\n","Epoch: 19 \tTraining Loss: 0.097582 \tValidation Loss: 0.124511\n","Epoch: 20 \tTraining Loss: 0.097546 \tValidation Loss: 0.124503\n","Epoch: 21 \tTraining Loss: 0.097514 \tValidation Loss: 0.124494\n","Epoch: 22 \tTraining Loss: 0.097486 \tValidation Loss: 0.124484\n","Epoch: 23 \tTraining Loss: 0.097461 \tValidation Loss: 0.124474\n","Epoch: 24 \tTraining Loss: 0.097438 \tValidation Loss: 0.124463\n","Epoch: 25 \tTraining Loss: 0.097418 \tValidation Loss: 0.124451\n","Epoch: 26 \tTraining Loss: 0.097400 \tValidation Loss: 0.124439\n","Epoch: 27 \tTraining Loss: 0.097384 \tValidation Loss: 0.124427\n","Epoch: 28 \tTraining Loss: 0.097370 \tValidation Loss: 0.124415\n","Epoch: 29 \tTraining Loss: 0.097357 \tValidation Loss: 0.124403\n","Epoch: 30 \tTraining Loss: 0.097345 \tValidation Loss: 0.124390\n","Epoch: 31 \tTraining Loss: 0.097334 \tValidation Loss: 0.124378\n","Epoch: 32 \tTraining Loss: 0.097324 \tValidation Loss: 0.124366\n","Epoch: 33 \tTraining Loss: 0.097316 \tValidation Loss: 0.124354\n","Epoch: 34 \tTraining Loss: 0.097308 \tValidation Loss: 0.124342\n","Epoch: 35 \tTraining Loss: 0.097300 \tValidation Loss: 0.124330\n","Epoch: 36 \tTraining Loss: 0.097294 \tValidation Loss: 0.124319\n","Epoch: 37 \tTraining Loss: 0.097288 \tValidation Loss: 0.124308\n","Epoch: 38 \tTraining Loss: 0.097282 \tValidation Loss: 0.124297\n","Epoch: 39 \tTraining Loss: 0.097277 \tValidation Loss: 0.124286\n","Epoch: 40 \tTraining Loss: 0.097272 \tValidation Loss: 0.124276\n","Epoch: 41 \tTraining Loss: 0.097268 \tValidation Loss: 0.124266\n","Epoch: 42 \tTraining Loss: 0.097264 \tValidation Loss: 0.124256\n","Epoch: 43 \tTraining Loss: 0.097260 \tValidation Loss: 0.124246\n","Epoch: 44 \tTraining Loss: 0.097256 \tValidation Loss: 0.124237\n","Epoch: 45 \tTraining Loss: 0.097253 \tValidation Loss: 0.124227\n","Epoch: 46 \tTraining Loss: 0.097250 \tValidation Loss: 0.124218\n","Epoch: 47 \tTraining Loss: 0.097247 \tValidation Loss: 0.124210\n","Epoch: 48 \tTraining Loss: 0.097244 \tValidation Loss: 0.124201\n","Epoch: 49 \tTraining Loss: 0.097241 \tValidation Loss: 0.124193\n","Epoch: 50 \tTraining Loss: 0.097239 \tValidation Loss: 0.124185\n","Epoch: 51 \tTraining Loss: 0.097237 \tValidation Loss: 0.124177\n","Epoch: 52 \tTraining Loss: 0.097234 \tValidation Loss: 0.124169\n","Epoch: 53 \tTraining Loss: 0.097232 \tValidation Loss: 0.124162\n","Epoch: 54 \tTraining Loss: 0.097230 \tValidation Loss: 0.124155\n","Epoch: 55 \tTraining Loss: 0.097228 \tValidation Loss: 0.124147\n","Epoch: 56 \tTraining Loss: 0.097226 \tValidation Loss: 0.124141\n","Epoch: 57 \tTraining Loss: 0.097224 \tValidation Loss: 0.124134\n","Epoch: 58 \tTraining Loss: 0.097222 \tValidation Loss: 0.124127\n","Epoch: 59 \tTraining Loss: 0.097220 \tValidation Loss: 0.124121\n","Epoch: 60 \tTraining Loss: 0.097219 \tValidation Loss: 0.124115\n","Epoch: 61 \tTraining Loss: 0.097217 \tValidation Loss: 0.124108\n","Epoch: 62 \tTraining Loss: 0.097215 \tValidation Loss: 0.124102\n","Epoch: 63 \tTraining Loss: 0.097214 \tValidation Loss: 0.124097\n","Epoch: 64 \tTraining Loss: 0.097212 \tValidation Loss: 0.124091\n","Epoch: 65 \tTraining Loss: 0.097211 \tValidation Loss: 0.124085\n","Epoch: 66 \tTraining Loss: 0.097209 \tValidation Loss: 0.124080\n","Epoch: 67 \tTraining Loss: 0.097208 \tValidation Loss: 0.124074\n","Epoch: 68 \tTraining Loss: 0.097206 \tValidation Loss: 0.124069\n","Epoch: 69 \tTraining Loss: 0.097205 \tValidation Loss: 0.124064\n","Epoch: 70 \tTraining Loss: 0.097204 \tValidation Loss: 0.124059\n","Epoch: 71 \tTraining Loss: 0.097202 \tValidation Loss: 0.124054\n","Epoch: 72 \tTraining Loss: 0.097201 \tValidation Loss: 0.124050\n","Epoch: 73 \tTraining Loss: 0.097200 \tValidation Loss: 0.124045\n","Epoch: 74 \tTraining Loss: 0.097198 \tValidation Loss: 0.124041\n","Epoch: 75 \tTraining Loss: 0.097197 \tValidation Loss: 0.124036\n","Epoch: 76 \tTraining Loss: 0.097196 \tValidation Loss: 0.124032\n","Epoch: 77 \tTraining Loss: 0.097194 \tValidation Loss: 0.124028\n","Epoch: 78 \tTraining Loss: 0.097193 \tValidation Loss: 0.124024\n","Epoch: 79 \tTraining Loss: 0.097192 \tValidation Loss: 0.124020\n","Epoch: 80 \tTraining Loss: 0.097191 \tValidation Loss: 0.124016\n","Epoch: 81 \tTraining Loss: 0.097189 \tValidation Loss: 0.124013\n","Epoch: 82 \tTraining Loss: 0.097188 \tValidation Loss: 0.124009\n","Epoch: 83 \tTraining Loss: 0.097187 \tValidation Loss: 0.124006\n","Epoch: 84 \tTraining Loss: 0.097186 \tValidation Loss: 0.124002\n","Epoch: 85 \tTraining Loss: 0.097185 \tValidation Loss: 0.123999\n","Epoch: 86 \tTraining Loss: 0.097183 \tValidation Loss: 0.123996\n","Epoch: 87 \tTraining Loss: 0.097182 \tValidation Loss: 0.123993\n","Epoch: 88 \tTraining Loss: 0.097181 \tValidation Loss: 0.123990\n","Epoch: 89 \tTraining Loss: 0.097180 \tValidation Loss: 0.123988\n","Epoch: 90 \tTraining Loss: 0.097178 \tValidation Loss: 0.123985\n","Epoch: 91 \tTraining Loss: 0.097177 \tValidation Loss: 0.123982\n","Epoch: 92 \tTraining Loss: 0.097176 \tValidation Loss: 0.123980\n","Epoch: 93 \tTraining Loss: 0.097175 \tValidation Loss: 0.123978\n","Epoch: 94 \tTraining Loss: 0.097173 \tValidation Loss: 0.123976\n","Epoch: 95 \tTraining Loss: 0.097172 \tValidation Loss: 0.123974\n","Epoch: 96 \tTraining Loss: 0.097171 \tValidation Loss: 0.123972\n","Epoch: 97 \tTraining Loss: 0.097170 \tValidation Loss: 0.123970\n","Epoch: 98 \tTraining Loss: 0.097168 \tValidation Loss: 0.123968\n","Epoch: 99 \tTraining Loss: 0.097167 \tValidation Loss: 0.123967\n"]}],"source":["train_model(modeln, optimizern, criterionn, traindn, valdn, num_epochs = 100)"]},{"cell_type":"code","execution_count":179,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["modeln.load_state_dict(torch.load('diabetesmodel.pt'))"]},{"cell_type":"code","execution_count":180,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model: 23.60%\n"]}],"source":["print(f\"Accuracy of the model: {100.0*eval_model(modeln, testdn):4.2f}%\")"]},{"cell_type":"markdown","metadata":{},"source":["En este caso, sí se ve una mejora significante para redes neuronales, ya que paso de 13.7% en todos los anteriores a 23.6%."]},{"cell_type":"markdown","metadata":{},"source":["#### Normalización utilizando atributos con ganancia mayor o igual a 10%"]},{"cell_type":"markdown","metadata":{},"source":["Para esta parte se utiliza el dataset normalizado y se toman los atributos que tienen ganancia de 10%."]},{"cell_type":"markdown","metadata":{},"source":["##### Algoritmos de ensamble"]},{"cell_type":"code","execution_count":181,"metadata":{},"outputs":[],"source":["xg1n = xn[['BMI', 'Age']]"]},{"cell_type":"code","execution_count":182,"metadata":{},"outputs":[],"source":["xg1ntr, xg1nte, yg1ntr, yg1nte = train_test_split(xg1n, y, test_size = 0.2, random_state = 42)\n","\n","# Entrenar un modelo de Random Forest\n","rf_classifier = RandomForestClassifier(random_state=42)\n","rf_classifier.fit(xg1ntr, yg1ntr)\n","rf_predictions = rf_classifier.predict(xg1nte)\n","\n","# Entrenar un modelo de AdaBoost\n","ada_classifier = AdaBoostClassifier(random_state=42)\n","ada_classifier.fit(xg1ntr, yg1ntr)\n","ada_predictions = ada_classifier.predict(xg1nte)\n","\n","# Entrenar un modelo de Gradient Boosting\n","gb_classifier = GradientBoostingClassifier(random_state=42)\n","gb_classifier.fit(xg1ntr, yg1ntr)\n","gb_predictions = gb_classifier.predict(xg1nte)\n","\n","# Entrenar un modelo de XGBoost\n","xgb_classifier = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n","xgb_classifier.fit(xg1ntr, yg1ntr)\n","xgb_predictions = xgb_classifier.predict(xg1nte)"]},{"cell_type":"code","execution_count":183,"metadata":{},"outputs":[{"data":{"text/plain":["{'Random Forest Accuracy': 0.8613213497319457,\n"," 'AdaBoost Accuracy': 0.8617549668874173,\n"," 'Gradient Boosting Accuracy': 0.8621885840428887,\n"," 'XGBoost Accuracy': 0.8613804793440555}"]},"execution_count":183,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluar el rendimiento de cada modelo\n","rf_accuracy = accuracy_score(yg1nte, rf_predictions)\n","ada_accuracy = accuracy_score(yg1nte, ada_predictions)\n","gb_accuracy = accuracy_score(yg1nte, gb_predictions)\n","xgb_accuracy = accuracy_score(yg1nte, xgb_predictions)\n","\n","# Mostrar la precisión de cada modelo\n","{'Random Forest Accuracy': rf_accuracy, 'AdaBoost Accuracy': ada_accuracy, 'Gradient Boosting Accuracy': gb_accuracy, 'XGBoost Accuracy': xgb_accuracy}"]},{"cell_type":"markdown","metadata":{},"source":["En este caso se mantienen en el rango de 86%, que es casi igual a los anteriores."]},{"cell_type":"markdown","metadata":{},"source":["##### Árbol de clasificación"]},{"cell_type":"code","execution_count":184,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" DecisionTreeClassifier Accuracy: 0.8614593188268685\n"]}],"source":["xg1ntr, xg1nte, yg1ntr, yg1nte = train_test_split(xg1n, y, test_size = 0.2, random_state = 42)\n","\n","model = DecisionTreeClassifier()\n","model.fit(xg1ntr, yg1ntr)\n","yg1npr = model.predict(xg1nte)\n","\n","accuracy = accuracy_score(yg1nte, yg1npr)\n","print(\" DecisionTreeClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["Aquí se obtiene un accuracy del 86.1%, igualando el resultado con los atributos con ganancia mayor o igual al 10%."]},{"cell_type":"markdown","metadata":{},"source":["##### Clasificación con k-vecinos"]},{"cell_type":"code","execution_count":185,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["KNeighborsClassifier Accuracy: 0.7711486912645853\n"]}],"source":["xg1ntr, xg1nte, yg1ntr, yg1nte = train_test_split(xg1n, y, test_size = 0.2, random_state = 42)\n","\n","xg1ntr = np.ascontiguousarray(xg1ntr)\n","xg1nte = np.ascontiguousarray(xg1nte)\n","\n","model = KNeighborsClassifier(n_neighbors=1)\n","model.fit(xg1ntr, yg1ntr)\n","yg1npr = model.predict(xg1nte)\n","\n","accuracy = accuracy_score(yg1nte, yg1npr)\n","print(\"KNeighborsClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["Por el contrario, aquí se obtuvo un accuracy del 77.1%, siendo el peor hasta ahora."]},{"cell_type":"markdown","metadata":{},"source":["##### Redes neuronales"]},{"cell_type":"code","execution_count":186,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BMI</th>\n","      <th>Age</th>\n","      <th>Diabetes_binary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.757936</td>\n","      <td>0.316900</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.511806</td>\n","      <td>-0.337933</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.057858</td>\n","      <td>0.316900</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.209174</td>\n","      <td>0.971733</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.663122</td>\n","      <td>0.971733</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>253675</th>\n","      <td>2.514516</td>\n","      <td>-0.992766</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253676</th>\n","      <td>-1.571019</td>\n","      <td>0.971733</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>253677</th>\n","      <td>-0.057858</td>\n","      <td>-1.975015</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253678</th>\n","      <td>-0.814438</td>\n","      <td>-0.337933</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253679</th>\n","      <td>-0.511806</td>\n","      <td>0.316900</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>253680 rows × 3 columns</p>\n","</div>"],"text/plain":["             BMI       Age  Diabetes_binary\n","0       1.757936  0.316900                0\n","1      -0.511806 -0.337933                0\n","2      -0.057858  0.316900                0\n","3      -0.209174  0.971733                0\n","4      -0.663122  0.971733                0\n","...          ...       ...              ...\n","253675  2.514516 -0.992766                0\n","253676 -1.571019  0.971733                1\n","253677 -0.057858 -1.975015                0\n","253678 -0.814438 -0.337933                0\n","253679 -0.511806  0.316900                1\n","\n","[253680 rows x 3 columns]"]},"execution_count":186,"metadata":{},"output_type":"execute_result"}],"source":["dg1n = xg1n.copy()\n","dg1n['Diabetes_binary'] = y.tolist()\n","dg1n"]},{"cell_type":"code","execution_count":187,"metadata":{},"outputs":[],"source":["dg1n = dg1n.sample(n = 10000, random_state = 42)\n","\n","traing1n = dg1n.iloc[:8000,:]   #Equivale al 80% de los datos.\n","valg1n = dg1n.iloc[8000:9000,:] #Equivale al 10% de los datos.\n","testg1n = dg1n.iloc[9000:,:]    #Equivale al 10% de los datos."]},{"cell_type":"code","execution_count":188,"metadata":{},"outputs":[],"source":["traintg1n = MyDataset(traing1n, 'Diabetes_binary')\n","testtg1n = MyDataset(testg1n, 'Diabetes_binary')\n","valtg1n = MyDataset(valg1n, 'Diabetes_binary')"]},{"cell_type":"code","execution_count":189,"metadata":{},"outputs":[],"source":["traindg1n = DataLoader(traintg1n, batch_size = 2,\n","                            shuffle = False,\n","                            num_workers = 0,\n","                            collate_fn = None,\n","                            pin_memory = False,)\n","\n","testdg1n = DataLoader(testtg1n, batch_size = 3,\n","                          shuffle = False,\n","                          num_workers = 0,\n","                          collate_fn = None,\n","                          pin_memory = False,)\n","\n","valdg1n = DataLoader(valtg1n, batch_size = 3,\n","                        shuffle = False,\n","                        num_workers = 0,\n","                        collate_fn = None,\n","                        pin_memory = False,)"]},{"cell_type":"code","execution_count":190,"metadata":{},"outputs":[],"source":["modelg1n = Net(num_inputs = 2, num_hidden = 3, num_outputs = 1)\n","\n","optimizerg1n = torch.optim.SGD(modelg1n.parameters(), lr = 0.01)\n","criteriong1n = nn.MSELoss()"]},{"cell_type":"code","execution_count":191,"metadata":{},"outputs":[{"data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=2, out_features=3, bias=True)\n","  (act_fn): Sigmoid()\n","  (fc2): Linear(in_features=3, out_features=1, bias=True)\n",")"]},"execution_count":191,"metadata":{},"output_type":"execute_result"}],"source":["modelg1n.to(device)"]},{"cell_type":"code","execution_count":192,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Loss: 0.109143 \tValidation Loss: 0.122894\n","Validation loss decreased (inf --> 0.122894).  Saving model ...\n","Epoch: 1 \tTraining Loss: 0.108320 \tValidation Loss: 0.122973\n","Epoch: 2 \tTraining Loss: 0.108241 \tValidation Loss: 0.123024\n","Epoch: 3 \tTraining Loss: 0.108165 \tValidation Loss: 0.123083\n","Epoch: 4 \tTraining Loss: 0.108095 \tValidation Loss: 0.123149\n","Epoch: 5 \tTraining Loss: 0.108033 \tValidation Loss: 0.123217\n","Epoch: 6 \tTraining Loss: 0.107980 \tValidation Loss: 0.123280\n","Epoch: 7 \tTraining Loss: 0.107936 \tValidation Loss: 0.123336\n","Epoch: 8 \tTraining Loss: 0.107899 \tValidation Loss: 0.123385\n","Epoch: 9 \tTraining Loss: 0.107867 \tValidation Loss: 0.123426\n","Epoch: 10 \tTraining Loss: 0.107840 \tValidation Loss: 0.123461\n","Epoch: 11 \tTraining Loss: 0.107815 \tValidation Loss: 0.123491\n","Epoch: 12 \tTraining Loss: 0.107794 \tValidation Loss: 0.123516\n","Epoch: 13 \tTraining Loss: 0.107775 \tValidation Loss: 0.123538\n","Epoch: 14 \tTraining Loss: 0.107757 \tValidation Loss: 0.123556\n","Epoch: 15 \tTraining Loss: 0.107742 \tValidation Loss: 0.123572\n","Epoch: 16 \tTraining Loss: 0.107727 \tValidation Loss: 0.123586\n","Epoch: 17 \tTraining Loss: 0.107714 \tValidation Loss: 0.123598\n","Epoch: 18 \tTraining Loss: 0.107702 \tValidation Loss: 0.123608\n","Epoch: 19 \tTraining Loss: 0.107690 \tValidation Loss: 0.123617\n","Epoch: 20 \tTraining Loss: 0.107680 \tValidation Loss: 0.123624\n","Epoch: 21 \tTraining Loss: 0.107670 \tValidation Loss: 0.123631\n","Epoch: 22 \tTraining Loss: 0.107661 \tValidation Loss: 0.123636\n","Epoch: 23 \tTraining Loss: 0.107653 \tValidation Loss: 0.123641\n","Epoch: 24 \tTraining Loss: 0.107645 \tValidation Loss: 0.123645\n","Epoch: 25 \tTraining Loss: 0.107637 \tValidation Loss: 0.123649\n","Epoch: 26 \tTraining Loss: 0.107630 \tValidation Loss: 0.123651\n","Epoch: 27 \tTraining Loss: 0.107624 \tValidation Loss: 0.123653\n","Epoch: 28 \tTraining Loss: 0.107618 \tValidation Loss: 0.123655\n","Epoch: 29 \tTraining Loss: 0.107612 \tValidation Loss: 0.123656\n","Epoch: 30 \tTraining Loss: 0.107607 \tValidation Loss: 0.123657\n","Epoch: 31 \tTraining Loss: 0.107601 \tValidation Loss: 0.123657\n","Epoch: 32 \tTraining Loss: 0.107596 \tValidation Loss: 0.123657\n","Epoch: 33 \tTraining Loss: 0.107591 \tValidation Loss: 0.123657\n","Epoch: 34 \tTraining Loss: 0.107587 \tValidation Loss: 0.123657\n","Epoch: 35 \tTraining Loss: 0.107582 \tValidation Loss: 0.123656\n","Epoch: 36 \tTraining Loss: 0.107578 \tValidation Loss: 0.123654\n","Epoch: 37 \tTraining Loss: 0.107574 \tValidation Loss: 0.123653\n","Epoch: 38 \tTraining Loss: 0.107570 \tValidation Loss: 0.123651\n","Epoch: 39 \tTraining Loss: 0.107566 \tValidation Loss: 0.123650\n","Epoch: 40 \tTraining Loss: 0.107562 \tValidation Loss: 0.123648\n","Epoch: 41 \tTraining Loss: 0.107559 \tValidation Loss: 0.123645\n","Epoch: 42 \tTraining Loss: 0.107555 \tValidation Loss: 0.123643\n","Epoch: 43 \tTraining Loss: 0.107551 \tValidation Loss: 0.123641\n","Epoch: 44 \tTraining Loss: 0.107548 \tValidation Loss: 0.123638\n","Epoch: 45 \tTraining Loss: 0.107544 \tValidation Loss: 0.123635\n","Epoch: 46 \tTraining Loss: 0.107541 \tValidation Loss: 0.123633\n","Epoch: 47 \tTraining Loss: 0.107537 \tValidation Loss: 0.123630\n","Epoch: 48 \tTraining Loss: 0.107534 \tValidation Loss: 0.123627\n","Epoch: 49 \tTraining Loss: 0.107530 \tValidation Loss: 0.123624\n","Epoch: 50 \tTraining Loss: 0.107527 \tValidation Loss: 0.123621\n","Epoch: 51 \tTraining Loss: 0.107524 \tValidation Loss: 0.123617\n","Epoch: 52 \tTraining Loss: 0.107520 \tValidation Loss: 0.123614\n","Epoch: 53 \tTraining Loss: 0.107517 \tValidation Loss: 0.123611\n","Epoch: 54 \tTraining Loss: 0.107514 \tValidation Loss: 0.123608\n","Epoch: 55 \tTraining Loss: 0.107510 \tValidation Loss: 0.123604\n","Epoch: 56 \tTraining Loss: 0.107507 \tValidation Loss: 0.123601\n","Epoch: 57 \tTraining Loss: 0.107503 \tValidation Loss: 0.123598\n","Epoch: 58 \tTraining Loss: 0.107500 \tValidation Loss: 0.123594\n","Epoch: 59 \tTraining Loss: 0.107497 \tValidation Loss: 0.123591\n","Epoch: 60 \tTraining Loss: 0.107493 \tValidation Loss: 0.123587\n","Epoch: 61 \tTraining Loss: 0.107490 \tValidation Loss: 0.123584\n","Epoch: 62 \tTraining Loss: 0.107487 \tValidation Loss: 0.123581\n","Epoch: 63 \tTraining Loss: 0.107483 \tValidation Loss: 0.123577\n","Epoch: 64 \tTraining Loss: 0.107480 \tValidation Loss: 0.123574\n","Epoch: 65 \tTraining Loss: 0.107476 \tValidation Loss: 0.123571\n","Epoch: 66 \tTraining Loss: 0.107473 \tValidation Loss: 0.123567\n","Epoch: 67 \tTraining Loss: 0.107470 \tValidation Loss: 0.123564\n","Epoch: 68 \tTraining Loss: 0.107466 \tValidation Loss: 0.123561\n","Epoch: 69 \tTraining Loss: 0.107463 \tValidation Loss: 0.123557\n","Epoch: 70 \tTraining Loss: 0.107459 \tValidation Loss: 0.123554\n","Epoch: 71 \tTraining Loss: 0.107456 \tValidation Loss: 0.123551\n","Epoch: 72 \tTraining Loss: 0.107452 \tValidation Loss: 0.123548\n","Epoch: 73 \tTraining Loss: 0.107449 \tValidation Loss: 0.123544\n","Epoch: 74 \tTraining Loss: 0.107445 \tValidation Loss: 0.123541\n","Epoch: 75 \tTraining Loss: 0.107442 \tValidation Loss: 0.123538\n","Epoch: 76 \tTraining Loss: 0.107438 \tValidation Loss: 0.123535\n","Epoch: 77 \tTraining Loss: 0.107435 \tValidation Loss: 0.123532\n","Epoch: 78 \tTraining Loss: 0.107431 \tValidation Loss: 0.123529\n","Epoch: 79 \tTraining Loss: 0.107428 \tValidation Loss: 0.123526\n","Epoch: 80 \tTraining Loss: 0.107424 \tValidation Loss: 0.123523\n","Epoch: 81 \tTraining Loss: 0.107421 \tValidation Loss: 0.123520\n","Epoch: 82 \tTraining Loss: 0.107417 \tValidation Loss: 0.123517\n","Epoch: 83 \tTraining Loss: 0.107414 \tValidation Loss: 0.123515\n","Epoch: 84 \tTraining Loss: 0.107410 \tValidation Loss: 0.123512\n","Epoch: 85 \tTraining Loss: 0.107407 \tValidation Loss: 0.123509\n","Epoch: 86 \tTraining Loss: 0.107403 \tValidation Loss: 0.123506\n","Epoch: 87 \tTraining Loss: 0.107400 \tValidation Loss: 0.123504\n","Epoch: 88 \tTraining Loss: 0.107397 \tValidation Loss: 0.123501\n","Epoch: 89 \tTraining Loss: 0.107393 \tValidation Loss: 0.123499\n","Epoch: 90 \tTraining Loss: 0.107390 \tValidation Loss: 0.123496\n","Epoch: 91 \tTraining Loss: 0.107386 \tValidation Loss: 0.123494\n","Epoch: 92 \tTraining Loss: 0.107383 \tValidation Loss: 0.123491\n","Epoch: 93 \tTraining Loss: 0.107380 \tValidation Loss: 0.123489\n","Epoch: 94 \tTraining Loss: 0.107376 \tValidation Loss: 0.123487\n","Epoch: 95 \tTraining Loss: 0.107373 \tValidation Loss: 0.123485\n","Epoch: 96 \tTraining Loss: 0.107370 \tValidation Loss: 0.123482\n","Epoch: 97 \tTraining Loss: 0.107367 \tValidation Loss: 0.123480\n","Epoch: 98 \tTraining Loss: 0.107363 \tValidation Loss: 0.123478\n","Epoch: 99 \tTraining Loss: 0.107360 \tValidation Loss: 0.123476\n"]}],"source":["train_model(modelg1n, optimizerg1n, criteriong1n, traindg1n, valdg1n, num_epochs = 100)"]},{"cell_type":"code","execution_count":193,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":193,"metadata":{},"output_type":"execute_result"}],"source":["modelg1n.load_state_dict(torch.load('diabetesmodel.pt'))"]},{"cell_type":"code","execution_count":194,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model: 15.50%\n"]}],"source":["print(f\"Accuracy of the model: {100.0*eval_model(modelg1n, testdg1n):4.2f}%\")"]},{"cell_type":"markdown","metadata":{},"source":["Aquí se obtiene una mejora a comparación de todos los otros exceptuando el resultado de la normalización sola."]},{"cell_type":"markdown","metadata":{},"source":["#### Normalización utilizando atributos con ganancia mayor o igual a 5%"]},{"cell_type":"markdown","metadata":{},"source":["Para esta parte se utiliza el dataset normalizado y se toman los atributos que tienen ganancia de 5%."]},{"cell_type":"markdown","metadata":{},"source":["##### Algoritmos de ensamble"]},{"cell_type":"code","execution_count":195,"metadata":{},"outputs":[],"source":["xg2n = xn[['BMI', 'Age', 'Income', 'HighBP_1', 'PhysHlth', 'GenHlth', 'Education', 'MentHlth']]"]},{"cell_type":"code","execution_count":196,"metadata":{},"outputs":[],"source":["xg2ntr, xg2nte, yg2ntr, yg2nte = train_test_split(xg2n, y, test_size = 0.2, random_state = 42)\n","\n","# Entrenar un modelo de Random Forest\n","rf_classifier = RandomForestClassifier(random_state=42)\n","rf_classifier.fit(xg2ntr, yg2ntr)\n","rf_predictions = rf_classifier.predict(xg2nte)\n","\n","# Entrenar un modelo de AdaBoost\n","ada_classifier = AdaBoostClassifier(random_state=42)\n","ada_classifier.fit(xg2ntr, yg2ntr)\n","ada_predictions = ada_classifier.predict(xg2nte)\n","\n","# Entrenar un modelo de Gradient Boosting\n","gb_classifier = GradientBoostingClassifier(random_state=42)\n","gb_classifier.fit(xg2ntr, yg2ntr)\n","gb_predictions = gb_classifier.predict(xg2nte)\n","\n","# Entrenar un modelo de XGBoost\n","xgb_classifier = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n","xgb_classifier.fit(xg2ntr, yg2ntr)\n","xgb_predictions = xgb_classifier.predict(xg2nte)"]},{"cell_type":"code","execution_count":197,"metadata":{},"outputs":[{"data":{"text/plain":["{'Random Forest Accuracy': 0.8472682119205298,\n"," 'AdaBoost Accuracy': 0.8649676758120467,\n"," 'Gradient Boosting Accuracy': 0.8650268054241564,\n"," 'XGBoost Accuracy': 0.864435509303059}"]},"execution_count":197,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluar el rendimiento de cada modelo\n","rf_accuracy = accuracy_score(yg2nte, rf_predictions)\n","ada_accuracy = accuracy_score(yg2nte, ada_predictions)\n","gb_accuracy = accuracy_score(yg2nte, gb_predictions)\n","xgb_accuracy = accuracy_score(yg2nte, xgb_predictions)\n","\n","# Mostrar la precisión de cada modelo\n","{'Random Forest Accuracy': rf_accuracy, 'AdaBoost Accuracy': ada_accuracy, 'Gradient Boosting Accuracy': gb_accuracy, 'XGBoost Accuracy': xgb_accuracy}"]},{"cell_type":"markdown","metadata":{},"source":["Aquí, otra vez, se mantienen al rededor del 86%, exceptuando Random Forest que disminuyo a 84.7%."]},{"cell_type":"markdown","metadata":{},"source":["##### Árbol de clasificación"]},{"cell_type":"code","execution_count":198,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" DecisionTreeClassifier Accuracy: 0.8173092084515926\n"]}],"source":["xg2ntr, xg2nte, yg2ntr, yg2nte = train_test_split(xg2n, y, test_size = 0.2, random_state = 42)\n","\n","model = DecisionTreeClassifier()\n","model.fit(xg2ntr, yg2ntr)\n","yg2npr = model.predict(xg2nte)\n","\n","accuracy = accuracy_score(yg2nte, yg2npr)\n","print(\" DecisionTreeClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["En este caso disminuyo a 81.7%."]},{"cell_type":"markdown","metadata":{},"source":["##### Clasificación con k-vecinos"]},{"cell_type":"code","execution_count":199,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["KNeighborsClassifier Accuracy: 0.8017187007253233\n"]}],"source":["xg2ntr, xg2nte, yg2ntr, yg2nte = train_test_split(xg2n, y, test_size = 0.2, random_state = 42)\n","\n","xg2ntr = np.ascontiguousarray(xg2ntr)\n","xg2nte = np.ascontiguousarray(xg2nte)\n","\n","model = KNeighborsClassifier(n_neighbors=1)\n","model.fit(xg2ntr, yg2ntr)\n","yg2npr = model.predict(xg2nte)\n","\n","accuracy = accuracy_score(yg2nte, yg2npr)\n","print(\"KNeighborsClassifier Accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["Para este se mantiene en el rango del 80%, como a gran mayoría."]},{"cell_type":"markdown","metadata":{},"source":["##### Redes neuronales"]},{"cell_type":"code","execution_count":200,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BMI</th>\n","      <th>Age</th>\n","      <th>Income</th>\n","      <th>HighBP_1</th>\n","      <th>PhysHlth</th>\n","      <th>GenHlth</th>\n","      <th>Education</th>\n","      <th>MentHlth</th>\n","      <th>Diabetes_binary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.757936</td>\n","      <td>0.316900</td>\n","      <td>-1.474487</td>\n","      <td>1.153688</td>\n","      <td>1.233999</td>\n","      <td>2.329121</td>\n","      <td>-1.065595</td>\n","      <td>1.998592</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.511806</td>\n","      <td>-0.337933</td>\n","      <td>-2.440138</td>\n","      <td>-0.866785</td>\n","      <td>-0.486592</td>\n","      <td>0.457294</td>\n","      <td>0.963272</td>\n","      <td>-0.429630</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.057858</td>\n","      <td>0.316900</td>\n","      <td>0.939638</td>\n","      <td>1.153688</td>\n","      <td>2.954590</td>\n","      <td>2.329121</td>\n","      <td>-1.065595</td>\n","      <td>3.617407</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.209174</td>\n","      <td>0.971733</td>\n","      <td>-0.026012</td>\n","      <td>1.153688</td>\n","      <td>-0.486592</td>\n","      <td>-0.478619</td>\n","      <td>-2.080028</td>\n","      <td>-0.429630</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.663122</td>\n","      <td>0.971733</td>\n","      <td>-0.991662</td>\n","      <td>1.153688</td>\n","      <td>-0.486592</td>\n","      <td>-0.478619</td>\n","      <td>-0.051162</td>\n","      <td>-0.024926</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>253675</th>\n","      <td>2.514516</td>\n","      <td>-0.992766</td>\n","      <td>0.456813</td>\n","      <td>1.153688</td>\n","      <td>0.086938</td>\n","      <td>0.457294</td>\n","      <td>0.963272</td>\n","      <td>-0.429630</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253676</th>\n","      <td>-1.571019</td>\n","      <td>0.971733</td>\n","      <td>-0.991662</td>\n","      <td>1.153688</td>\n","      <td>-0.486592</td>\n","      <td>1.393207</td>\n","      <td>-3.094461</td>\n","      <td>-0.429630</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>253677</th>\n","      <td>-0.057858</td>\n","      <td>-1.975015</td>\n","      <td>-1.957312</td>\n","      <td>-0.866785</td>\n","      <td>-0.486592</td>\n","      <td>-1.414532</td>\n","      <td>-0.051162</td>\n","      <td>-0.429630</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253678</th>\n","      <td>-0.814438</td>\n","      <td>-0.337933</td>\n","      <td>-2.440138</td>\n","      <td>1.153688</td>\n","      <td>-0.486592</td>\n","      <td>0.457294</td>\n","      <td>-0.051162</td>\n","      <td>-0.429630</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253679</th>\n","      <td>-0.511806</td>\n","      <td>0.316900</td>\n","      <td>-1.957312</td>\n","      <td>1.153688</td>\n","      <td>-0.486592</td>\n","      <td>-0.478619</td>\n","      <td>0.963272</td>\n","      <td>-0.429630</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>253680 rows × 9 columns</p>\n","</div>"],"text/plain":["             BMI       Age    Income  HighBP_1  PhysHlth   GenHlth  Education  \\\n","0       1.757936  0.316900 -1.474487  1.153688  1.233999  2.329121  -1.065595   \n","1      -0.511806 -0.337933 -2.440138 -0.866785 -0.486592  0.457294   0.963272   \n","2      -0.057858  0.316900  0.939638  1.153688  2.954590  2.329121  -1.065595   \n","3      -0.209174  0.971733 -0.026012  1.153688 -0.486592 -0.478619  -2.080028   \n","4      -0.663122  0.971733 -0.991662  1.153688 -0.486592 -0.478619  -0.051162   \n","...          ...       ...       ...       ...       ...       ...        ...   \n","253675  2.514516 -0.992766  0.456813  1.153688  0.086938  0.457294   0.963272   \n","253676 -1.571019  0.971733 -0.991662  1.153688 -0.486592  1.393207  -3.094461   \n","253677 -0.057858 -1.975015 -1.957312 -0.866785 -0.486592 -1.414532  -0.051162   \n","253678 -0.814438 -0.337933 -2.440138  1.153688 -0.486592  0.457294  -0.051162   \n","253679 -0.511806  0.316900 -1.957312  1.153688 -0.486592 -0.478619   0.963272   \n","\n","        MentHlth  Diabetes_binary  \n","0       1.998592                0  \n","1      -0.429630                0  \n","2       3.617407                0  \n","3      -0.429630                0  \n","4      -0.024926                0  \n","...          ...              ...  \n","253675 -0.429630                0  \n","253676 -0.429630                1  \n","253677 -0.429630                0  \n","253678 -0.429630                0  \n","253679 -0.429630                1  \n","\n","[253680 rows x 9 columns]"]},"execution_count":200,"metadata":{},"output_type":"execute_result"}],"source":["dg2n = xg2n.copy()\n","dg2n['Diabetes_binary'] = y.tolist()\n","dg2n"]},{"cell_type":"code","execution_count":201,"metadata":{},"outputs":[],"source":["dg2n = dg2n.sample(n = 10000, random_state = 42)\n","\n","traing2n = dg2n.iloc[:8000,:]   #Equivale al 80% de los datos.\n","valg2n = dg2n.iloc[8000:9000,:] #Equivale al 10% de los datos.\n","testg2n = dg2n.iloc[9000:,:]    #Equivale al 10% de los datos."]},{"cell_type":"code","execution_count":202,"metadata":{},"outputs":[],"source":["traintg2n = MyDataset(traing2n, 'Diabetes_binary')\n","testtg2n = MyDataset(testg2n, 'Diabetes_binary')\n","valtg2n = MyDataset(valg2n, 'Diabetes_binary')"]},{"cell_type":"code","execution_count":203,"metadata":{},"outputs":[],"source":["traindg2n = DataLoader(traintg2n, batch_size = 2,\n","                            shuffle = False,\n","                            num_workers = 0,\n","                            collate_fn = None,\n","                            pin_memory = False,)\n","\n","testdg2n = DataLoader(testtg2n, batch_size = 3,\n","                          shuffle = False,\n","                          num_workers = 0,\n","                          collate_fn = None,\n","                          pin_memory = False,)\n","\n","valdg2n = DataLoader(valtg2n, batch_size = 3,\n","                        shuffle = False,\n","                        num_workers = 0,\n","                        collate_fn = None,\n","                        pin_memory = False,)"]},{"cell_type":"code","execution_count":204,"metadata":{},"outputs":[],"source":["modelg2n = Net(num_inputs = 8, num_hidden = 3, num_outputs = 1)\n","\n","optimizerg2n = torch.optim.SGD(modelg2n.parameters(), lr = 0.01)\n","criteriong2n = nn.MSELoss()"]},{"cell_type":"code","execution_count":205,"metadata":{},"outputs":[{"data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=8, out_features=3, bias=True)\n","  (act_fn): Sigmoid()\n","  (fc2): Linear(in_features=3, out_features=1, bias=True)\n",")"]},"execution_count":205,"metadata":{},"output_type":"execute_result"}],"source":["modelg2n.to(device)"]},{"cell_type":"code","execution_count":206,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","c:\\Users\\alejo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Loss: 0.110338 \tValidation Loss: 0.121141\n","Validation loss decreased (inf --> 0.121141).  Saving model ...\n","Epoch: 1 \tTraining Loss: 0.102520 \tValidation Loss: 0.122892\n","Epoch: 2 \tTraining Loss: 0.101808 \tValidation Loss: 0.123433\n","Epoch: 3 \tTraining Loss: 0.101508 \tValidation Loss: 0.123774\n","Epoch: 4 \tTraining Loss: 0.101340 \tValidation Loss: 0.123990\n","Epoch: 5 \tTraining Loss: 0.101216 \tValidation Loss: 0.124140\n","Epoch: 6 \tTraining Loss: 0.101109 \tValidation Loss: 0.124252\n","Epoch: 7 \tTraining Loss: 0.101011 \tValidation Loss: 0.124342\n","Epoch: 8 \tTraining Loss: 0.100916 \tValidation Loss: 0.124417\n","Epoch: 9 \tTraining Loss: 0.100825 \tValidation Loss: 0.124479\n","Epoch: 10 \tTraining Loss: 0.100735 \tValidation Loss: 0.124532\n","Epoch: 11 \tTraining Loss: 0.100648 \tValidation Loss: 0.124578\n","Epoch: 12 \tTraining Loss: 0.100563 \tValidation Loss: 0.124617\n","Epoch: 13 \tTraining Loss: 0.100481 \tValidation Loss: 0.124652\n","Epoch: 14 \tTraining Loss: 0.100403 \tValidation Loss: 0.124682\n","Epoch: 15 \tTraining Loss: 0.100329 \tValidation Loss: 0.124708\n","Epoch: 16 \tTraining Loss: 0.100261 \tValidation Loss: 0.124731\n","Epoch: 17 \tTraining Loss: 0.100197 \tValidation Loss: 0.124752\n","Epoch: 18 \tTraining Loss: 0.100139 \tValidation Loss: 0.124770\n","Epoch: 19 \tTraining Loss: 0.100086 \tValidation Loss: 0.124785\n","Epoch: 20 \tTraining Loss: 0.100039 \tValidation Loss: 0.124799\n","Epoch: 21 \tTraining Loss: 0.099996 \tValidation Loss: 0.124812\n","Epoch: 22 \tTraining Loss: 0.099958 \tValidation Loss: 0.124823\n","Epoch: 23 \tTraining Loss: 0.099925 \tValidation Loss: 0.124833\n","Epoch: 24 \tTraining Loss: 0.099895 \tValidation Loss: 0.124842\n","Epoch: 25 \tTraining Loss: 0.099869 \tValidation Loss: 0.124850\n","Epoch: 26 \tTraining Loss: 0.099846 \tValidation Loss: 0.124857\n","Epoch: 27 \tTraining Loss: 0.099825 \tValidation Loss: 0.124864\n","Epoch: 28 \tTraining Loss: 0.099807 \tValidation Loss: 0.124871\n","Epoch: 29 \tTraining Loss: 0.099792 \tValidation Loss: 0.124877\n","Epoch: 30 \tTraining Loss: 0.099778 \tValidation Loss: 0.124882\n","Epoch: 31 \tTraining Loss: 0.099766 \tValidation Loss: 0.124888\n","Epoch: 32 \tTraining Loss: 0.099755 \tValidation Loss: 0.124892\n","Epoch: 33 \tTraining Loss: 0.099745 \tValidation Loss: 0.124897\n","Epoch: 34 \tTraining Loss: 0.099737 \tValidation Loss: 0.124901\n","Epoch: 35 \tTraining Loss: 0.099729 \tValidation Loss: 0.124905\n","Epoch: 36 \tTraining Loss: 0.099722 \tValidation Loss: 0.124908\n","Epoch: 37 \tTraining Loss: 0.099716 \tValidation Loss: 0.124911\n","Epoch: 38 \tTraining Loss: 0.099710 \tValidation Loss: 0.124914\n","Epoch: 39 \tTraining Loss: 0.099705 \tValidation Loss: 0.124916\n","Epoch: 40 \tTraining Loss: 0.099700 \tValidation Loss: 0.124918\n","Epoch: 41 \tTraining Loss: 0.099695 \tValidation Loss: 0.124920\n","Epoch: 42 \tTraining Loss: 0.099691 \tValidation Loss: 0.124921\n","Epoch: 43 \tTraining Loss: 0.099687 \tValidation Loss: 0.124922\n","Epoch: 44 \tTraining Loss: 0.099684 \tValidation Loss: 0.124923\n","Epoch: 45 \tTraining Loss: 0.099680 \tValidation Loss: 0.124924\n","Epoch: 46 \tTraining Loss: 0.099677 \tValidation Loss: 0.124924\n","Epoch: 47 \tTraining Loss: 0.099674 \tValidation Loss: 0.124924\n","Epoch: 48 \tTraining Loss: 0.099671 \tValidation Loss: 0.124924\n","Epoch: 49 \tTraining Loss: 0.099668 \tValidation Loss: 0.124923\n","Epoch: 50 \tTraining Loss: 0.099665 \tValidation Loss: 0.124923\n","Epoch: 51 \tTraining Loss: 0.099662 \tValidation Loss: 0.124922\n","Epoch: 52 \tTraining Loss: 0.099660 \tValidation Loss: 0.124921\n","Epoch: 53 \tTraining Loss: 0.099657 \tValidation Loss: 0.124920\n","Epoch: 54 \tTraining Loss: 0.099655 \tValidation Loss: 0.124918\n","Epoch: 55 \tTraining Loss: 0.099653 \tValidation Loss: 0.124917\n","Epoch: 56 \tTraining Loss: 0.099650 \tValidation Loss: 0.124915\n","Epoch: 57 \tTraining Loss: 0.099648 \tValidation Loss: 0.124913\n","Epoch: 58 \tTraining Loss: 0.099646 \tValidation Loss: 0.124911\n","Epoch: 59 \tTraining Loss: 0.099644 \tValidation Loss: 0.124909\n","Epoch: 60 \tTraining Loss: 0.099642 \tValidation Loss: 0.124906\n","Epoch: 61 \tTraining Loss: 0.099640 \tValidation Loss: 0.124904\n","Epoch: 62 \tTraining Loss: 0.099638 \tValidation Loss: 0.124901\n","Epoch: 63 \tTraining Loss: 0.099636 \tValidation Loss: 0.124899\n","Epoch: 64 \tTraining Loss: 0.099634 \tValidation Loss: 0.124896\n","Epoch: 65 \tTraining Loss: 0.099632 \tValidation Loss: 0.124892\n","Epoch: 66 \tTraining Loss: 0.099630 \tValidation Loss: 0.124889\n","Epoch: 67 \tTraining Loss: 0.099628 \tValidation Loss: 0.124886\n","Epoch: 68 \tTraining Loss: 0.099626 \tValidation Loss: 0.124882\n","Epoch: 69 \tTraining Loss: 0.099624 \tValidation Loss: 0.124879\n","Epoch: 70 \tTraining Loss: 0.099622 \tValidation Loss: 0.124875\n","Epoch: 71 \tTraining Loss: 0.099620 \tValidation Loss: 0.124871\n","Epoch: 72 \tTraining Loss: 0.099618 \tValidation Loss: 0.124867\n","Epoch: 73 \tTraining Loss: 0.099616 \tValidation Loss: 0.124863\n","Epoch: 74 \tTraining Loss: 0.099615 \tValidation Loss: 0.124859\n","Epoch: 75 \tTraining Loss: 0.099613 \tValidation Loss: 0.124855\n","Epoch: 76 \tTraining Loss: 0.099611 \tValidation Loss: 0.124851\n","Epoch: 77 \tTraining Loss: 0.099609 \tValidation Loss: 0.124846\n","Epoch: 78 \tTraining Loss: 0.099607 \tValidation Loss: 0.124842\n","Epoch: 79 \tTraining Loss: 0.099605 \tValidation Loss: 0.124837\n","Epoch: 80 \tTraining Loss: 0.099602 \tValidation Loss: 0.124833\n","Epoch: 81 \tTraining Loss: 0.099600 \tValidation Loss: 0.124828\n","Epoch: 82 \tTraining Loss: 0.099598 \tValidation Loss: 0.124824\n","Epoch: 83 \tTraining Loss: 0.099596 \tValidation Loss: 0.124819\n","Epoch: 84 \tTraining Loss: 0.099594 \tValidation Loss: 0.124814\n","Epoch: 85 \tTraining Loss: 0.099592 \tValidation Loss: 0.124809\n","Epoch: 86 \tTraining Loss: 0.099590 \tValidation Loss: 0.124805\n","Epoch: 87 \tTraining Loss: 0.099587 \tValidation Loss: 0.124800\n","Epoch: 88 \tTraining Loss: 0.099585 \tValidation Loss: 0.124795\n","Epoch: 89 \tTraining Loss: 0.099583 \tValidation Loss: 0.124790\n","Epoch: 90 \tTraining Loss: 0.099580 \tValidation Loss: 0.124786\n","Epoch: 91 \tTraining Loss: 0.099578 \tValidation Loss: 0.124781\n","Epoch: 92 \tTraining Loss: 0.099575 \tValidation Loss: 0.124776\n","Epoch: 93 \tTraining Loss: 0.099573 \tValidation Loss: 0.124772\n","Epoch: 94 \tTraining Loss: 0.099570 \tValidation Loss: 0.124768\n","Epoch: 95 \tTraining Loss: 0.099568 \tValidation Loss: 0.124763\n","Epoch: 96 \tTraining Loss: 0.099565 \tValidation Loss: 0.124759\n","Epoch: 97 \tTraining Loss: 0.099562 \tValidation Loss: 0.124755\n","Epoch: 98 \tTraining Loss: 0.099560 \tValidation Loss: 0.124751\n","Epoch: 99 \tTraining Loss: 0.099557 \tValidation Loss: 0.124747\n"]}],"source":["train_model(modelg2n, optimizerg2n, criteriong2n, traindg2n, valdg2n, num_epochs = 100)"]},{"cell_type":"code","execution_count":207,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":207,"metadata":{},"output_type":"execute_result"}],"source":["modelg2n.load_state_dict(torch.load('diabetesmodel.pt'))"]},{"cell_type":"code","execution_count":208,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model: 17.20%\n"]}],"source":["print(f\"Accuracy of the model: {100.0*eval_model(modelg2n, testdg2n):4.2f}%\")"]},{"cell_type":"markdown","metadata":{},"source":["Y por ultimo, aqui tambien aumenta el accuracy, pero no sobrepasa el 23.6% obtenido antes."]},{"cell_type":"markdown","metadata":{},"source":["Y como conclusión, para los algoritmos de ensamble, los mejores resultados fueron los siguientes:\n","* Random Forest: 86.1% con los atributos con ganancia mayor o igual al 10% o con el dataset normalizado y usando los atributos con ganancia mayor o igual al 10%.\n","* AdaBoost: 86.6% con el modelo inicial o el dataset normalizado.\n","* Gradient Boosting: 86.7% con el modelo inicial o el dataset normalizado.\n","* XGBoost: 86.6% con el modelo inicial o el dataset normalizado.\n","\n","Ahora, para el árbol de clasificación, el mejor resultado fue de 86.1% con los atributos con ganancia mayor o igual al 10% o con el dataset normalizado y usando los atributos con ganancia mayor o igual al 10%.\n","\n","Para k-vecinos fue de 80.9% con los atributos con ganancia mayor o igual al 10%.\n","\n","Y por último, para redes neuronales el mejor fue de 23.6% con el dataset normalizado."]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"}},"nbformat":4,"nbformat_minor":0}
